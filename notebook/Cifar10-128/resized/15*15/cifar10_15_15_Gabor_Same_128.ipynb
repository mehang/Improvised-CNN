{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10-15*15-Gabor-Same-128.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlZspEaURCCuQc2v7EL6IB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehang/Improvised-CNN/blob/master/notebook/Cifar10-128/resized/15*15/cifar10_15_15_Gabor_Same_128.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF1EkZD42P2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d6a48d-c170-4c79-8c52-f92f5c9a2af5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpDP685m5NwT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pathlib\n",
        "import time\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTmcRyRr5QKX"
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/Mehang\\ Rai/cifar10-32.zip -d cifar10-32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reMzYfyY5R2N"
      },
      "source": [
        "ITERATION = 1\n",
        "IMAGE_WIDTH=32\n",
        "IMAGE_HEIGHT=32\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3\n",
        "RANDOM_SEED = [42, 42, 57, 48, 86, 7, 15, 28, 39, 52][ITERATION-1]\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 10\n",
        "EPOCHS = 1000\n",
        "GABOR_LAYER_INDEX = 0\n",
        "GABOR_WIDTH = 3\n",
        "GABOR_HEIGHT = 3\n",
        "GABOR_SIZE = (GABOR_WIDTH, GABOR_HEIGHT)\n",
        "NUM_RECEPTIVE_FILTERS = 32\n",
        "TRAIN_DIR = \"cifar10-32/cifar10-32/train/\"\n",
        "TEST_DIR = \"cifar10-32/cifar10-32/test/\"\n",
        "# TEST_DIR = \"cifar100_128_fine/cifar100_128_fine/train/\"\n",
        "# TRAIN_DIR = \"cifar100_128_fine/cifar100_128_fine/test/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb1IVevN5Wha",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "7b8ef45c-6723-499f-c36d-2f482a1809f8"
      },
      "source": [
        "filenames = os.listdir(TRAIN_DIR)\n",
        "categories = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    categories.append(category)\n",
        "\n",
        "train_df = pd.DataFrame({\n",
        "    'filename': filenames,\n",
        "    'category': categories\n",
        "})\n",
        "\n",
        "filenames = os.listdir(TEST_DIR)\n",
        "categories = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    categories.append(category)\n",
        "\n",
        "validate_df = pd.DataFrame({\n",
        "    'filename': filenames,\n",
        "    'category': categories\n",
        "})"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4baafd4c24e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcategory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcategories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cifar10-32/cifar10-32/train/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0v84unt5XGC"
      },
      "source": [
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)\n",
        "total_train = train_df.shape[0]\n",
        "total_validate = validate_df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz8CVvZI5Y7w"
      },
      "source": [
        "train_df['category'].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJMj2lnj5a0C"
      },
      "source": [
        "validate_df['category'].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8Z0K9t05dXt"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    # rotation_range=40,\n",
        "    # width_shift_range=0.2,\n",
        "    # height_shift_range=0.2,\n",
        "    # shear_range=0.2,\n",
        "    # zoom_range=0.2,\n",
        "    # horizontal_flip=True,\n",
        "    rescale=1./255,\n",
        ")\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df, \n",
        "    TRAIN_DIR, \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKpE5pri5fPi"
      },
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    validate_df, \n",
        "    TEST_DIR, \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38cSQe645g0B"
      },
      "source": [
        "print(train_df.shape)\n",
        "print(validate_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un9ETu_r5iap"
      },
      "source": [
        "import math\n",
        "\n",
        "def get_gabor_filters(inchannels, outchannels, kernel_size = (3,3)):\n",
        "    delta = 1e-4\n",
        "    freqs = (math.pi/2)*(math.sqrt(2)**(-np.random.randint(0,5, (outchannels, inchannels))))\n",
        "    thetas = (math.pi/8)*np.random.randint(0,8, (outchannels, inchannels))\n",
        "    sigmas = math.pi/(freqs)\n",
        "    psis = math.pi * np.random.rand(outchannels, inchannels)\n",
        "    x0, y0 = np.ceil(np.array(kernel_size)/2)    \n",
        "    \n",
        "    y, x = np.meshgrid(\n",
        "            np.linspace(-x0 + 1, x0 + 0, kernel_size[0]),\n",
        "            np.linspace(-y0 + 1, y0 + 0, kernel_size[1]),\n",
        "    )\n",
        "    filterbank = []\n",
        "    \n",
        "    for i in range(outchannels):\n",
        "        for j in range(inchannels):\n",
        "            freq = freqs[i][j]\n",
        "            theta = thetas[i][j]\n",
        "            sigma = sigmas[i][j]\n",
        "            psi = psis[i][j]\n",
        "            \n",
        "            rotx = x * np.cos(theta) + y * np.sin(theta)\n",
        "            roty = -x * np.sin(theta) + y * np.cos(theta)\n",
        "\n",
        "            g = np.exp(\n",
        "                -0.5 * ((rotx ** 2 + roty ** 2) / (sigma + delta) ** 2)\n",
        "            )\n",
        "            g = g * np.cos(freq * rotx + psi)\n",
        "#             g = g / (2 * math.pi * (sigma ** 2))\n",
        "#             g = gabor_kernel(frequency=freq, bandwidth=sigma, theta=theta, offset=psi, n_stds=0).real\n",
        "            filterbank.append(g)\n",
        "    return filterbank\n",
        "\n",
        "filterbank = get_gabor_filters(3, NUM_RECEPTIVE_FILTERS, GABOR_SIZE)\n",
        "\n",
        "fig = plt.subplots(8, len(filterbank)//8, figsize=(22,22))\n",
        "for i,gf in enumerate(filterbank):\n",
        "    plt.subplot(8, len(filterbank)//8, i+1)\n",
        "    plt.imshow(gf, cmap='gray')\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PyJT1cO5nMi"
      },
      "source": [
        "train_generator.image_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN7LoNr45vHV"
      },
      "source": [
        "NUM_CLASSES = len(train_df['category'].value_counts())\n",
        "print(NUM_CLASSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GBU8MJT5xDb"
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Activation\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "classifier = None\n",
        "classifier = Sequential([\n",
        "    layers.Conv2D(NUM_RECEPTIVE_FILTERS, kernel_size=GABOR_SIZE, strides=(1,1), activation='relu', name=\"GaborLayer\", input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    Dropout(0.25),\n",
        "    layers.Conv2D(64, kernel_size=(3,3), strides=(2,2), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    Dropout(0.25),\n",
        "    layers.Conv2D(128, kernel_size=(3,3), strides=(2,2), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    Dropout(0.25),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    Dropout(0.25),\n",
        "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KtfjYOY5ywT"
      },
      "source": [
        "cnnl1 = classifier.layers[GABOR_LAYER_INDEX].name   # get the name of the first conv layer\n",
        "W = classifier.get_layer(name=cnnl1).get_weights()[0]   #get the filters\n",
        "wshape = W.shape  #save the original shape\n",
        "gabor_filters = W\n",
        "for kernel_index in range(wshape[3]):\n",
        "    for channel_index in range(3):\n",
        "        gabor_filters[:,:,channel_index, kernel_index] = filterbank[kernel_index]\n",
        "\n",
        "classifier.get_layer(name=cnnl1).set_weights([gabor_filters, classifier.get_layer(name=cnnl1).get_weights()[1]])\n",
        "filter_layers = []\n",
        "for i in range(NUM_RECEPTIVE_FILTERS):\n",
        "    for j in range(3):\n",
        "        filter_layers.append(np.reshape(W[:,:,j, i], GABOR_SIZE))\n",
        "for i,gf in enumerate(filter_layers):\n",
        "    plt.subplot(8, len(filter_layers)//8, i+1)\n",
        "    plt.imshow(gf, cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.savefig('cifar10-{}-initial-gabor-same-kernel-{}.png'.format(ITERATION,GABOR_WIDTH), dpi=350, bbox_inches='tight')\n",
        "\n",
        "import copy\n",
        "untrained_layers = copy.deepcopy(classifier.get_layer(name=classifier.layers[GABOR_LAYER_INDEX].name).get_weights())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PJYxPvi57Kv"
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10,  \n",
        "                              min_delta=1e-4, mode='min', verbose=1)\n",
        "stop_alg = EarlyStopping(monitor='val_loss', patience=35, \n",
        "                         restore_best_weights=True, verbose=1)\n",
        "callbacks = [stop_alg, reduce_lr]\n",
        "opt = Adam(learning_rate=0.001)\n",
        "classifier.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', 'AUC'])\n",
        "\n",
        "start = time.perf_counter()\n",
        "hist = classifier.fit(\n",
        "    train_generator, \n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_validate//BATCH_SIZE,\n",
        "    steps_per_epoch=total_train//BATCH_SIZE,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "finish = time.perf_counter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIKKW_ra59hd"
      },
      "source": [
        "classifier.layers[GABOR_LAYER_INDEX].name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmyM1rq65_nn"
      },
      "source": [
        "print(\"Start time = {}\".format(start))\n",
        "print(\"Finish time = {}\".format(finish))\n",
        "print(\"Training time = {}\".format(finish-start))\n",
        "hist.history['start_time'] = start\n",
        "hist.history['finish_time'] = finish\n",
        "hist.history['train_time'] = finish-start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9i-Tz-Y6BMh"
      },
      "source": [
        "import pickle\n",
        "\n",
        "trained_layers = copy.deepcopy(classifier.get_layer(name=classifier.layers[GABOR_LAYER_INDEX].name).get_weights())\n",
        "hist.history['untrained_layers'] = untrained_layers\n",
        "hist.history['trained_layers'] = trained_layers\n",
        "\n",
        "with open('cifar10-{}-history-gabor-same-kernel-{}.p'.format(ITERATION, GABOR_HEIGHT), 'wb') as fp:\n",
        "  pickle.dump(hist.history, fp, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYyG-QL_6Fo2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.plot(hist.history['loss'], color='#785ef0')\n",
        "plt.plot(hist.history['val_loss'], color='#dc267f')\n",
        "plt.title('Model Loss Progress')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Set', 'Test Set'], loc='upper right')\n",
        "plt.savefig('cifar10-{}-loss-gabor-same-kernel-{}.png'.format(ITERATION, GABOR_WIDTH), dpi=350, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaSqA3oR6IX6"
      },
      "source": [
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.plot(hist.history['accuracy'], color='#785ef0')\n",
        "plt.plot(hist.history['val_accuracy'], color='#dc267f')\n",
        "plt.title('Model Accuracy Progress')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Set', 'Test Set'], loc='upper right')\n",
        "plt.savefig('cifar10-{}-accuracy-gabor-same-kernel-{}.png'.format(ITERATION, GABOR_WIDTH), dpi=350, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE5sW1_u6L1P"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "cnnl1 = classifier.layers[GABOR_LAYER_INDEX].name   # get the name of the first conv layer\n",
        "W = classifier.get_layer(name=cnnl1).get_weights()[0]   #get the filters\n",
        "wshape = W.shape  #save the original shape\n",
        "\n",
        "# this part will scale to [0, 1] for visualization purposes\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(W.reshape(-1,1))\n",
        "W = scaler.transform(W.reshape(-1,1))\n",
        "W = W.reshape(wshape)\n",
        "\n",
        "fig, axs = plt.subplots(8,NUM_RECEPTIVE_FILTERS//8, figsize=(24,24))\n",
        "fig.subplots_adjust(hspace = .25, wspace=.001)\n",
        "axs = axs.ravel()\n",
        "for i in range(W.shape[-1]):\n",
        "  # we reshape to a 3D (RGB) image shape and display\n",
        "  h = np.reshape(W[:,:,:,i], (GABOR_WIDTH,GABOR_HEIGHT,3))\n",
        "  axs[i].imshow(h)\n",
        "  axs[i].set_title('Filter ' + str(i))    \n",
        "plt.savefig(\"cifar10-{}-filters-gabor-same-kernel-{}.png\".format(ITERATION, GABOR_WIDTH), bbox_inches='tight', dpi=350)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U08TDyFP6Och"
      },
      "source": [
        "cnnl1 = classifier.layers[GABOR_LAYER_INDEX].name   # get the name of the first conv layer\n",
        "W = classifier.get_layer(name=cnnl1).get_weights()[0]\n",
        "plt.hist(W.ravel(), bins=100)\n",
        "print(np.min(W),np.max(W))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uquVDHlj6Qda"
      },
      "source": [
        "filter_layers = []\n",
        "for i in range(NUM_RECEPTIVE_FILTERS):\n",
        "    for j in range(3):\n",
        "        filter_layers.append(np.reshape(W[:,:,j, i], GABOR_SIZE))\n",
        "for i,gf in enumerate(filter_layers):\n",
        "    plt.subplot(8, (W.shape[3]*3)//8, i+1)\n",
        "    plt.imshow(gf, cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.savefig(\"cifar10-{}-channelwise-gabor-same-filters-kernel-{}.png\".format(ITERATION, GABOR_WIDTH), bbox_inches='tight', dpi=350)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IirOi0H86THU"
      },
      "source": [
        "!cp cifar10-1-initial-gabor-same-kernel-3.png /content/drive/My\\ Drive/Mehang\\ Rai/analysis/image-size/32/3/cifar10-32/1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJY5QRrZ6YaI"
      },
      "source": [
        "!cp cifar10-1-history-gabor-same-kernel-3.p /content/drive/My\\ Drive/Mehang\\ Rai/analysis/image-size/32/3/cifar10-32/1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmEFzcB-6elm"
      },
      "source": [
        "!cp cifar10-1-loss-gabor-same-kernel-3.png /content/drive/My\\ Drive/Mehang\\ Rai/analysis/image-size/32/3/cifar10-32/1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVdNEtje6jKX"
      },
      "source": [
        "!cp cifar10-1-accuracy-gabor-same-kernel-3.png /content/drive/My\\ Drive/Mehang\\ Rai/analysis/image-size/32/3/cifar10-32/1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRMfa5A_6lCW"
      },
      "source": [
        "!cp cifar10-1-filters-gabor-same-kernel-3.png /content/drive/My\\ Drive/Mehang\\ Rai/analysis/image-size/32/3/cifar10-32/1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Lf7ZnJO6maF"
      },
      "source": [
        "!cp cifar10-1-channelwise-gabor-same-filters-kernel-3.png /content/drive/My\\ Drive/Mehang\\ Rai/analysis/image-size/32/3/cifar10-32/1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRWg-tFB3m1a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}