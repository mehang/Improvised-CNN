{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gabor_kernel\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "x_test shape: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import math\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 100\n",
    "IMAGE_SIZE = 32\n",
    "NUM_OF_CLASSES = 10\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# x_train = x_train.astype('float32') / 255.0\n",
    "# x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 100\n",
    "IMAGE_SIZE = 32\n",
    "NUM_OF_CLASSES = 10\n",
    "\n",
    "def process_dataset(image, label):\n",
    "    # Normalize images to have a mean of 0 and standard deviation of 1\n",
    "#     image = tf.image.per_image_standardization(image)\n",
    "    \n",
    "#     image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # Resize images from 32x32 to 227x227\n",
    "#     image = tf.image.resize(image, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "\n",
    "#     image = image/255.0\n",
    "         \n",
    "#     label = tf.one_hot(tf.cast(label, tf.int32), NUM_OF_CLASSES)\n",
    "        \n",
    "    return image, label\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "def construct_dataset(ds):\n",
    "    ds = ds.shuffle(buffer_size=BATCH_SIZE)\n",
    "    ds = ds.map(process_dataset,num_parallel_calls=AUTOTUNE)\n",
    "#     ds=ds.repeat()\n",
    "    ds = ds.batch(BATCH_SIZE, drop_remainder=False)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_data = construct_dataset(train_data)\n",
    "test_data = construct_dataset(test_data)\n",
    "\n",
    "steps_per_epoch=math.ceil(50000/BATCH_SIZE)\n",
    "validation_steps=math.ceil(10000/BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 15, 15, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 225,354\n",
      "Trainable params: 224,714\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Activation\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "# dimensionality of input and latent encoded representations\n",
    "inpt_dim = (32, 32, 3)\n",
    "\n",
    "inpt_img = Input(shape=inpt_dim)\n",
    "\n",
    "# rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape = inpt_dim )(inpt_img)\n",
    "\n",
    "# Block 1\n",
    "cl1 = Conv2D(64, (3, 3), strides=(2, 2),activation='relu', input_shape = inpt_dim)(inpt_img)\n",
    "bnl2 = BatchNormalization()(cl1)\n",
    "# afl3 = Activation('relu')(bnl2)\n",
    "pl4 = MaxPooling2D(pool_size = (2, 2))(bnl2)\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "cl5 = Conv2D(128, (3, 3), strides=(1, 1), activation='relu')(pl4)\n",
    "bnl6 = BatchNormalization()(cl5)\n",
    "# afl7 = Activation('relu')(bnl6)\n",
    "pl8 = MaxPooling2D(pool_size = (2, 2))(bnl6)\n",
    "bnl9 = BatchNormalization()(pl8)\n",
    "\n",
    "# Step 3 - Flattening\n",
    "fl10 = Flatten()(bnl9)\n",
    "\n",
    "# Step 4 - Full connection\n",
    "dol11 = Dropout(0.5)(fl10)\n",
    "dl12 = Dense(units = 256, activation = 'relu')(dol11)\n",
    "dol13 = Dropout(0.2)(dl12)\n",
    "dl14 = Dense(units = 64, activation = 'relu')(dol13)\n",
    "dol15 = Dropout(0.1)(dl14)\n",
    "output = Dense(units = 10, activation = 'sigmoid')(dol15)\n",
    "\n",
    "classifier = Model(inpt_img, output)\n",
    "\n",
    "# Compiling the CNN\n",
    "opt = RMSprop(learning_rate=0.001)\n",
    "# opt = Adam(learning_rate=0.01)\n",
    "\n",
    "classifier.compile(optimizer = opt, loss ='binary_crossentropy', \n",
    "                   metrics = ['accuracy'])\n",
    "\n",
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.2659 - accuracy: 0.3861 - val_loss: 0.2258 - val_accuracy: 0.4841\n",
      "Epoch 2/1000\n",
      "500/500 [==============================] - 37s 73ms/step - loss: 0.2204 - accuracy: 0.5047 - val_loss: 0.2394 - val_accuracy: 0.4426\n",
      "Epoch 3/1000\n",
      "500/500 [==============================] - 38s 75ms/step - loss: 0.2032 - accuracy: 0.5486 - val_loss: 0.1916 - val_accuracy: 0.5782\n",
      "Epoch 4/1000\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.1937 - accuracy: 0.5765 - val_loss: 0.1962 - val_accuracy: 0.5560\n",
      "Epoch 5/1000\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.1860 - accuracy: 0.5935 - val_loss: 0.1886 - val_accuracy: 0.5797\n",
      "Epoch 6/1000\n",
      "500/500 [==============================] - 38s 75ms/step - loss: 0.1797 - accuracy: 0.6110 - val_loss: 0.1887 - val_accuracy: 0.5888\n",
      "Epoch 7/1000\n",
      "500/500 [==============================] - 45s 89ms/step - loss: 0.1746 - accuracy: 0.6241 - val_loss: 0.1711 - val_accuracy: 0.6325\n",
      "Epoch 8/1000\n",
      "500/500 [==============================] - 49s 97ms/step - loss: 0.1696 - accuracy: 0.6355 - val_loss: 0.1914 - val_accuracy: 0.5771\n",
      "Epoch 9/1000\n",
      "500/500 [==============================] - 53s 105ms/step - loss: 0.1657 - accuracy: 0.6444 - val_loss: 0.1616 - val_accuracy: 0.6508\n",
      "Epoch 10/1000\n",
      "500/500 [==============================] - 53s 107ms/step - loss: 0.1626 - accuracy: 0.6533 - val_loss: 0.1693 - val_accuracy: 0.6314\n",
      "Epoch 11/1000\n",
      "500/500 [==============================] - 53s 105ms/step - loss: 0.1600 - accuracy: 0.6616 - val_loss: 0.1779 - val_accuracy: 0.6086\n",
      "Epoch 12/1000\n",
      "500/500 [==============================] - 49s 98ms/step - loss: 0.1570 - accuracy: 0.6669 - val_loss: 0.1747 - val_accuracy: 0.6168\n",
      "Epoch 13/1000\n",
      "500/500 [==============================] - 54s 108ms/step - loss: 0.1546 - accuracy: 0.6740 - val_loss: 0.2076 - val_accuracy: 0.5785\n",
      "Epoch 14/1000\n",
      "500/500 [==============================] - 56s 111ms/step - loss: 0.1529 - accuracy: 0.6770 - val_loss: 0.1626 - val_accuracy: 0.6468\n",
      "Epoch 15/1000\n",
      "500/500 [==============================] - 64s 128ms/step - loss: 0.1498 - accuracy: 0.6852 - val_loss: 0.1559 - val_accuracy: 0.6693\n",
      "Epoch 16/1000\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 0.1480 - accuracy: 0.6879 - val_loss: 0.1723 - val_accuracy: 0.6371\n",
      "Epoch 17/1000\n",
      "500/500 [==============================] - 64s 128ms/step - loss: 0.1463 - accuracy: 0.6920 - val_loss: 0.1525 - val_accuracy: 0.6774\n",
      "Epoch 18/1000\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 0.1455 - accuracy: 0.6961 - val_loss: 0.1775 - val_accuracy: 0.6250\n",
      "Epoch 19/1000\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 0.1434 - accuracy: 0.6986 - val_loss: 0.1504 - val_accuracy: 0.6778\n",
      "Epoch 20/1000\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.1433 - accuracy: 0.6988 - val_loss: 0.1695 - val_accuracy: 0.6337\n",
      "Epoch 21/1000\n",
      "500/500 [==============================] - 64s 129ms/step - loss: 0.1405 - accuracy: 0.7062 - val_loss: 0.1555 - val_accuracy: 0.6675\n",
      "Epoch 22/1000\n",
      "500/500 [==============================] - 66s 132ms/step - loss: 0.1395 - accuracy: 0.7093 - val_loss: 0.1648 - val_accuracy: 0.6481\n",
      "Epoch 23/1000\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.1383 - accuracy: 0.7101 - val_loss: 0.1536 - val_accuracy: 0.6688\n",
      "Epoch 24/1000\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.1384 - accuracy: 0.7123 - val_loss: 0.1593 - val_accuracy: 0.6518\n",
      "Epoch 25/1000\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 0.1363 - accuracy: 0.7180 - val_loss: 0.1669 - val_accuracy: 0.6305\n",
      "Epoch 26/1000\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 0.1353 - accuracy: 0.7184 - val_loss: 0.1480 - val_accuracy: 0.6870\n",
      "Epoch 27/1000\n",
      "500/500 [==============================] - 64s 129ms/step - loss: 0.1343 - accuracy: 0.7218 - val_loss: 0.1431 - val_accuracy: 0.6937\n",
      "Epoch 28/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.1342 - accuracy: 0.7190 - val_loss: 0.1421 - val_accuracy: 0.7022\n",
      "Epoch 29/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.1334 - accuracy: 0.7223 - val_loss: 0.1452 - val_accuracy: 0.6867\n",
      "Epoch 30/1000\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.1318 - accuracy: 0.7267 - val_loss: 0.1446 - val_accuracy: 0.6925\n",
      "Epoch 31/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.1314 - accuracy: 0.7287 - val_loss: 0.1682 - val_accuracy: 0.6365\n",
      "Epoch 32/1000\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 0.1300 - accuracy: 0.7301 - val_loss: 0.1475 - val_accuracy: 0.6919\n",
      "Epoch 33/1000\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.1292 - accuracy: 0.7331 - val_loss: 0.1575 - val_accuracy: 0.6696\n",
      "Epoch 34/1000\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 0.1283 - accuracy: 0.7354 - val_loss: 0.1579 - val_accuracy: 0.6579\n",
      "Epoch 35/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.1280 - accuracy: 0.7361 - val_loss: 0.1454 - val_accuracy: 0.6916\n",
      "Epoch 36/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.1276 - accuracy: 0.7386 - val_loss: 0.1567 - val_accuracy: 0.6640\n",
      "Epoch 37/1000\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 0.1264 - accuracy: 0.7384 - val_loss: 0.1524 - val_accuracy: 0.6720\n",
      "Epoch 38/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1258 - accuracy: 0.7399\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.1258 - accuracy: 0.7399 - val_loss: 0.1427 - val_accuracy: 0.7038\n",
      "Epoch 39/1000\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.1179 - accuracy: 0.7589 - val_loss: 0.1431 - val_accuracy: 0.6994\n",
      "Epoch 40/1000\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.1175 - accuracy: 0.7600 - val_loss: 0.1341 - val_accuracy: 0.7210\n",
      "Epoch 41/1000\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.1155 - accuracy: 0.7629 - val_loss: 0.1401 - val_accuracy: 0.7049\n",
      "Epoch 42/1000\n",
      "500/500 [==============================] - 64s 128ms/step - loss: 0.1156 - accuracy: 0.7658 - val_loss: 0.1440 - val_accuracy: 0.6938\n",
      "Epoch 43/1000\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 0.1143 - accuracy: 0.7664 - val_loss: 0.1439 - val_accuracy: 0.7025\n",
      "Epoch 44/1000\n",
      "500/500 [==============================] - 64s 128ms/step - loss: 0.1136 - accuracy: 0.7690 - val_loss: 0.1361 - val_accuracy: 0.7182\n",
      "Epoch 45/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.1122 - accuracy: 0.7709 - val_loss: 0.1354 - val_accuracy: 0.7159\n",
      "Epoch 46/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.1125 - accuracy: 0.7708 - val_loss: 0.1404 - val_accuracy: 0.7084\n",
      "Epoch 47/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.1116 - accuracy: 0.7742 - val_loss: 0.1339 - val_accuracy: 0.7230\n",
      "Epoch 48/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.1109 - accuracy: 0.7752 - val_loss: 0.1352 - val_accuracy: 0.7254\n",
      "Epoch 49/1000\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 0.1107 - accuracy: 0.7764 - val_loss: 0.1321 - val_accuracy: 0.7290\n",
      "Epoch 50/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.1103 - accuracy: 0.7790 - val_loss: 0.1452 - val_accuracy: 0.6923\n",
      "Epoch 51/1000\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.1096 - accuracy: 0.7774 - val_loss: 0.1376 - val_accuracy: 0.7120\n",
      "Epoch 52/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.1093 - accuracy: 0.7780 - val_loss: 0.1319 - val_accuracy: 0.7274\n",
      "Epoch 53/1000\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 0.1093 - accuracy: 0.7795 - val_loss: 0.1319 - val_accuracy: 0.7261\n",
      "Epoch 54/1000\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.1095 - accuracy: 0.7765 - val_loss: 0.1340 - val_accuracy: 0.7226\n",
      "Epoch 55/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 60s 120ms/step - loss: 0.1077 - accuracy: 0.7824 - val_loss: 0.1347 - val_accuracy: 0.7226\n",
      "Epoch 56/1000\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 0.1071 - accuracy: 0.7822 - val_loss: 0.1415 - val_accuracy: 0.7014\n",
      "Epoch 57/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.1083 - accuracy: 0.7784 - val_loss: 0.1440 - val_accuracy: 0.7009\n",
      "Epoch 58/1000\n",
      "500/500 [==============================] - 65s 131ms/step - loss: 0.1073 - accuracy: 0.7829 - val_loss: 0.1414 - val_accuracy: 0.7014\n",
      "Epoch 59/1000\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 0.1070 - accuracy: 0.7835 - val_loss: 0.1366 - val_accuracy: 0.7195\n",
      "Epoch 60/1000\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 0.1071 - accuracy: 0.7842 - val_loss: 0.1413 - val_accuracy: 0.7002\n",
      "Epoch 61/1000\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 0.1065 - accuracy: 0.7872 - val_loss: 0.1421 - val_accuracy: 0.7016\n",
      "Epoch 62/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.7865\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 0.1058 - accuracy: 0.7865 - val_loss: 0.1413 - val_accuracy: 0.7083\n",
      "Epoch 63/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.1021 - accuracy: 0.7935 - val_loss: 0.1283 - val_accuracy: 0.7351\n",
      "Epoch 64/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.1021 - accuracy: 0.7956 - val_loss: 0.1300 - val_accuracy: 0.7329\n",
      "Epoch 65/1000\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 0.1008 - accuracy: 0.7976 - val_loss: 0.1283 - val_accuracy: 0.7386\n",
      "Epoch 66/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.1015 - accuracy: 0.7955 - val_loss: 0.1289 - val_accuracy: 0.7321\n",
      "Epoch 67/1000\n",
      "500/500 [==============================] - 65s 130ms/step - loss: 0.0999 - accuracy: 0.7987 - val_loss: 0.1310 - val_accuracy: 0.7288\n",
      "Epoch 68/1000\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 0.0989 - accuracy: 0.7989 - val_loss: 0.1285 - val_accuracy: 0.7379\n",
      "Epoch 69/1000\n",
      "500/500 [==============================] - 64s 129ms/step - loss: 0.0990 - accuracy: 0.8010 - val_loss: 0.1323 - val_accuracy: 0.7312\n",
      "Epoch 70/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.0995 - accuracy: 0.8001 - val_loss: 0.1313 - val_accuracy: 0.7261\n",
      "Epoch 71/1000\n",
      "500/500 [==============================] - 56s 111ms/step - loss: 0.0990 - accuracy: 0.8011 - val_loss: 0.1294 - val_accuracy: 0.7347\n",
      "Epoch 72/1000\n",
      "500/500 [==============================] - 56s 113ms/step - loss: 0.0989 - accuracy: 0.8016 - val_loss: 0.1283 - val_accuracy: 0.7383\n",
      "Epoch 73/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.8033\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.0982 - accuracy: 0.8033 - val_loss: 0.1314 - val_accuracy: 0.7295\n",
      "Epoch 74/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 0.0963 - accuracy: 0.8064 - val_loss: 0.1263 - val_accuracy: 0.7414\n",
      "Epoch 75/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0975 - accuracy: 0.8055 - val_loss: 0.1277 - val_accuracy: 0.7398\n",
      "Epoch 76/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.0953 - accuracy: 0.8088 - val_loss: 0.1261 - val_accuracy: 0.7458\n",
      "Epoch 77/1000\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 0.0967 - accuracy: 0.8044 - val_loss: 0.1275 - val_accuracy: 0.7384\n",
      "Epoch 78/1000\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.0959 - accuracy: 0.8076 - val_loss: 0.1264 - val_accuracy: 0.7448\n",
      "Epoch 79/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.0950 - accuracy: 0.8097 - val_loss: 0.1260 - val_accuracy: 0.7444\n",
      "Epoch 80/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.0952 - accuracy: 0.8102 - val_loss: 0.1264 - val_accuracy: 0.7430\n",
      "Epoch 81/1000\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 0.0949 - accuracy: 0.8111 - val_loss: 0.1281 - val_accuracy: 0.7408\n",
      "Epoch 82/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 0.0944 - accuracy: 0.8103 - val_loss: 0.1270 - val_accuracy: 0.7421\n",
      "Epoch 83/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0947 - accuracy: 0.8114 - val_loss: 0.1258 - val_accuracy: 0.7450\n",
      "Epoch 84/1000\n",
      "500/500 [==============================] - 58s 115ms/step - loss: 0.0946 - accuracy: 0.8105 - val_loss: 0.1256 - val_accuracy: 0.7462\n",
      "Epoch 85/1000\n",
      "500/500 [==============================] - 56s 112ms/step - loss: 0.0951 - accuracy: 0.8104 - val_loss: 0.1280 - val_accuracy: 0.7391\n",
      "Epoch 86/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0944 - accuracy: 0.8109 - val_loss: 0.1270 - val_accuracy: 0.7444\n",
      "Epoch 87/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 0.0949 - accuracy: 0.8099 - val_loss: 0.1277 - val_accuracy: 0.7412\n",
      "Epoch 88/1000\n",
      "500/500 [==============================] - 58s 115ms/step - loss: 0.0943 - accuracy: 0.8111 - val_loss: 0.1258 - val_accuracy: 0.7447\n",
      "Epoch 89/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 0.0938 - accuracy: 0.8136 - val_loss: 0.1272 - val_accuracy: 0.7429\n",
      "Epoch 90/1000\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 0.0948 - accuracy: 0.8104 - val_loss: 0.1260 - val_accuracy: 0.7465\n",
      "Epoch 91/1000\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 0.0936 - accuracy: 0.8130 - val_loss: 0.1276 - val_accuracy: 0.7421\n",
      "Epoch 92/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 0.0940 - accuracy: 0.8114 - val_loss: 0.1264 - val_accuracy: 0.7455\n",
      "Epoch 93/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.0940 - accuracy: 0.8126 - val_loss: 0.1263 - val_accuracy: 0.7459\n",
      "Epoch 94/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.8137\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 0.0938 - accuracy: 0.8137 - val_loss: 0.1295 - val_accuracy: 0.7342\n",
      "Epoch 95/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0922 - accuracy: 0.8166 - val_loss: 0.1254 - val_accuracy: 0.7498\n",
      "Epoch 96/1000\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 0.0922 - accuracy: 0.8154 - val_loss: 0.1251 - val_accuracy: 0.7472\n",
      "Epoch 97/1000\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 0.0934 - accuracy: 0.8143 - val_loss: 0.1257 - val_accuracy: 0.7469\n",
      "Epoch 98/1000\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 0.0924 - accuracy: 0.8155 - val_loss: 0.1253 - val_accuracy: 0.7482\n",
      "Epoch 99/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.0925 - accuracy: 0.8170 - val_loss: 0.1246 - val_accuracy: 0.7485\n",
      "Epoch 100/1000\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 0.0921 - accuracy: 0.8144 - val_loss: 0.1251 - val_accuracy: 0.7495\n",
      "Epoch 101/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 0.0906 - accuracy: 0.8207 - val_loss: 0.1259 - val_accuracy: 0.7481\n",
      "Epoch 102/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 0.0915 - accuracy: 0.8164 - val_loss: 0.1256 - val_accuracy: 0.7466\n",
      "Epoch 103/1000\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 0.0920 - accuracy: 0.8158 - val_loss: 0.1252 - val_accuracy: 0.7467\n",
      "Epoch 104/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 0.0916 - accuracy: 0.8188 - val_loss: 0.1254 - val_accuracy: 0.7469\n",
      "Epoch 105/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 0.0929 - accuracy: 0.8160 - val_loss: 0.1261 - val_accuracy: 0.7438\n",
      "Epoch 106/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.0915 - accuracy: 0.8185 - val_loss: 0.1259 - val_accuracy: 0.7467\n",
      "Epoch 107/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0912 - accuracy: 0.8187 - val_loss: 0.1252 - val_accuracy: 0.7486\n",
      "Epoch 108/1000\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 0.0915 - accuracy: 0.8188 - val_loss: 0.1260 - val_accuracy: 0.7440\n",
      "Epoch 109/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.8185\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 0.0914 - accuracy: 0.8185 - val_loss: 0.1251 - val_accuracy: 0.7494\n",
      "Epoch 110/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.0911 - accuracy: 0.8187 - val_loss: 0.1248 - val_accuracy: 0.7489\n",
      "Epoch 111/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.0911 - accuracy: 0.8181 - val_loss: 0.1247 - val_accuracy: 0.7506\n",
      "Epoch 112/1000\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 0.0919 - accuracy: 0.8156 - val_loss: 0.1243 - val_accuracy: 0.7490\n",
      "Epoch 113/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0913 - accuracy: 0.8183 - val_loss: 0.1245 - val_accuracy: 0.7477\n",
      "Epoch 114/1000\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.0908 - accuracy: 0.8217 - val_loss: 0.1242 - val_accuracy: 0.7507\n",
      "Epoch 115/1000\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 0.0911 - accuracy: 0.8190 - val_loss: 0.1247 - val_accuracy: 0.7487\n",
      "Epoch 116/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.0905 - accuracy: 0.8200 - val_loss: 0.1246 - val_accuracy: 0.7495\n",
      "Epoch 117/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.0901 - accuracy: 0.8216 - val_loss: 0.1248 - val_accuracy: 0.7505\n",
      "Epoch 118/1000\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 0.0912 - accuracy: 0.8162 - val_loss: 0.1249 - val_accuracy: 0.7486\n",
      "Epoch 119/1000\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 0.0898 - accuracy: 0.8215 - val_loss: 0.1244 - val_accuracy: 0.7487\n",
      "Epoch 120/1000\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 0.0899 - accuracy: 0.8220 - val_loss: 0.1248 - val_accuracy: 0.7488\n",
      "Epoch 121/1000\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 0.0910 - accuracy: 0.8184 - val_loss: 0.1249 - val_accuracy: 0.7477\n",
      "Epoch 122/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.0910 - accuracy: 0.8207 - val_loss: 0.1243 - val_accuracy: 0.7483\n",
      "Epoch 123/1000\n",
      "500/500 [==============================] - 64s 128ms/step - loss: 0.0907 - accuracy: 0.8192 - val_loss: 0.1242 - val_accuracy: 0.7494\n",
      "Epoch 124/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 0.8216\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 0.0902 - accuracy: 0.8216 - val_loss: 0.1242 - val_accuracy: 0.7495\n",
      "Epoch 125/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.0900 - accuracy: 0.8223 - val_loss: 0.1240 - val_accuracy: 0.7514\n",
      "Epoch 126/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0902 - accuracy: 0.8198 - val_loss: 0.1242 - val_accuracy: 0.7498\n",
      "Epoch 127/1000\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 0.0902 - accuracy: 0.8231 - val_loss: 0.1242 - val_accuracy: 0.7499\n",
      "Epoch 128/1000\n",
      "500/500 [==============================] - 65s 129ms/step - loss: 0.0889 - accuracy: 0.8215 - val_loss: 0.1241 - val_accuracy: 0.7500\n",
      "Epoch 129/1000\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 0.0892 - accuracy: 0.8232 - val_loss: 0.1244 - val_accuracy: 0.7493\n",
      "Epoch 130/1000\n",
      "500/500 [==============================] - 64s 128ms/step - loss: 0.0897 - accuracy: 0.8214 - val_loss: 0.1241 - val_accuracy: 0.7510\n",
      "Epoch 131/1000\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.0902 - accuracy: 0.8203 - val_loss: 0.1246 - val_accuracy: 0.7497\n",
      "Epoch 132/1000\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 0.0904 - accuracy: 0.8197 - val_loss: 0.1245 - val_accuracy: 0.7492\n",
      "Epoch 133/1000\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 0.0899 - accuracy: 0.8224 - val_loss: 0.1243 - val_accuracy: 0.7501\n",
      "Epoch 134/1000\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 0.0896 - accuracy: 0.8214 - val_loss: 0.1242 - val_accuracy: 0.7495\n",
      "Epoch 135/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.8217\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.0903 - accuracy: 0.8217 - val_loss: 0.1243 - val_accuracy: 0.7497\n",
      "Epoch 136/1000\n",
      "500/500 [==============================] - 51s 102ms/step - loss: 0.0899 - accuracy: 0.8204 - val_loss: 0.1241 - val_accuracy: 0.7494\n",
      "Epoch 137/1000\n",
      "500/500 [==============================] - 51s 101ms/step - loss: 0.0904 - accuracy: 0.8213 - val_loss: 0.1240 - val_accuracy: 0.7505\n",
      "Epoch 138/1000\n",
      "500/500 [==============================] - 47s 94ms/step - loss: 0.0898 - accuracy: 0.8225 - val_loss: 0.1240 - val_accuracy: 0.7496\n",
      "Epoch 139/1000\n",
      "500/500 [==============================] - 48s 96ms/step - loss: 0.0897 - accuracy: 0.8217 - val_loss: 0.1240 - val_accuracy: 0.7500\n",
      "Epoch 140/1000\n",
      "500/500 [==============================] - 47s 94ms/step - loss: 0.0897 - accuracy: 0.8218 - val_loss: 0.1240 - val_accuracy: 0.7501\n",
      "Epoch 141/1000\n",
      "500/500 [==============================] - 47s 94ms/step - loss: 0.0897 - accuracy: 0.8218 - val_loss: 0.1239 - val_accuracy: 0.7507\n",
      "Epoch 142/1000\n",
      "500/500 [==============================] - 49s 98ms/step - loss: 0.0898 - accuracy: 0.8215 - val_loss: 0.1240 - val_accuracy: 0.7501\n",
      "Epoch 143/1000\n",
      "500/500 [==============================] - 47s 93ms/step - loss: 0.0899 - accuracy: 0.8222 - val_loss: 0.1239 - val_accuracy: 0.7497\n",
      "Epoch 144/1000\n",
      "500/500 [==============================] - 47s 94ms/step - loss: 0.0897 - accuracy: 0.8223 - val_loss: 0.1241 - val_accuracy: 0.7501\n",
      "Epoch 145/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.8217\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "500/500 [==============================] - 47s 95ms/step - loss: 0.0891 - accuracy: 0.8217 - val_loss: 0.1241 - val_accuracy: 0.7506\n",
      "Epoch 146/1000\n",
      "500/500 [==============================] - 48s 95ms/step - loss: 0.0898 - accuracy: 0.8219 - val_loss: 0.1240 - val_accuracy: 0.7509\n",
      "Epoch 147/1000\n",
      "500/500 [==============================] - 49s 97ms/step - loss: 0.0898 - accuracy: 0.8217 - val_loss: 0.1240 - val_accuracy: 0.7512\n",
      "Epoch 148/1000\n",
      "500/500 [==============================] - 48s 96ms/step - loss: 0.0903 - accuracy: 0.8208 - val_loss: 0.1240 - val_accuracy: 0.7518\n",
      "Epoch 149/1000\n",
      "500/500 [==============================] - 46s 93ms/step - loss: 0.0904 - accuracy: 0.8198 - val_loss: 0.1240 - val_accuracy: 0.7512\n",
      "Epoch 150/1000\n",
      "500/500 [==============================] - 47s 94ms/step - loss: 0.0903 - accuracy: 0.8201 - val_loss: 0.1240 - val_accuracy: 0.7507\n",
      "Epoch 151/1000\n",
      "500/500 [==============================] - 48s 96ms/step - loss: 0.0899 - accuracy: 0.8207 - val_loss: 0.1240 - val_accuracy: 0.7507\n",
      "Epoch 152/1000\n",
      "500/500 [==============================] - 50s 100ms/step - loss: 0.0891 - accuracy: 0.8230 - val_loss: 0.1241 - val_accuracy: 0.7500\n",
      "Epoch 153/1000\n",
      "500/500 [==============================] - 45s 91ms/step - loss: 0.0890 - accuracy: 0.8239 - val_loss: 0.1240 - val_accuracy: 0.7497\n",
      "Epoch 154/1000\n",
      "500/500 [==============================] - 46s 93ms/step - loss: 0.0895 - accuracy: 0.8217 - val_loss: 0.1241 - val_accuracy: 0.7499\n",
      "Epoch 155/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0895 - accuracy: 0.8220\n",
      "Epoch 00155: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "500/500 [==============================] - 49s 98ms/step - loss: 0.0895 - accuracy: 0.8220 - val_loss: 0.1241 - val_accuracy: 0.7505\n",
      "Epoch 156/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 47s 94ms/step - loss: 0.0886 - accuracy: 0.8235 - val_loss: 0.1241 - val_accuracy: 0.7501\n",
      "Epoch 157/1000\n",
      "500/500 [==============================] - 46s 92ms/step - loss: 0.0900 - accuracy: 0.8231 - val_loss: 0.1241 - val_accuracy: 0.7498\n",
      "Epoch 158/1000\n",
      "500/500 [==============================] - 46s 93ms/step - loss: 0.0894 - accuracy: 0.8225 - val_loss: 0.1240 - val_accuracy: 0.7498\n",
      "Epoch 159/1000\n",
      "500/500 [==============================] - 46s 92ms/step - loss: 0.0893 - accuracy: 0.8225 - val_loss: 0.1240 - val_accuracy: 0.7493\n",
      "Epoch 160/1000\n",
      "500/500 [==============================] - 47s 95ms/step - loss: 0.0905 - accuracy: 0.8186 - val_loss: 0.1240 - val_accuracy: 0.7503\n",
      "Epoch 161/1000\n",
      "500/500 [==============================] - 46s 92ms/step - loss: 0.0890 - accuracy: 0.8238 - val_loss: 0.1240 - val_accuracy: 0.7500\n",
      "Epoch 162/1000\n",
      "248/500 [=============>................] - ETA: 22s - loss: 0.0903 - accuracy: 0.8233"
     ]
    }
   ],
   "source": [
    "# Fitting the CNN to the images\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10,  \n",
    "                              min_delta=1e-4, mode='min', verbose=1)\n",
    "\n",
    "stop_alg = EarlyStopping(monitor='val_loss', patience=35, \n",
    "                         restore_best_weights=True, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "hist = classifier.fit(train_data,  epochs=1000, \n",
    "                   callbacks=[stop_alg, reduce_lr], \n",
    "                      validation_steps=validation_steps,\n",
    "                      steps_per_epoch=steps_per_epoch,\n",
    "                   validation_data=test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
