{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gabor_kernel\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "x_test shape: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import math\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 100\n",
    "IMAGE_SIZE = 32\n",
    "NUM_OF_CLASSES = 10\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# x_train = x_train.astype('float32') / 255.0\n",
    "# x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 100\n",
    "IMAGE_SIZE = 32\n",
    "NUM_OF_CLASSES = 10\n",
    "\n",
    "def process_dataset(image, label):\n",
    "    # Normalize images to have a mean of 0 and standard deviation of 1\n",
    "#     image = tf.image.per_image_standardization(image)\n",
    "    \n",
    "#     image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # Resize images from 32x32 to 227x227\n",
    "#     image = tf.image.resize(image, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "\n",
    "#     image = image/255.0\n",
    "         \n",
    "    label = tf.one_hot(tf.cast(label, tf.int32), NUM_OF_CLASSES)\n",
    "        \n",
    "    return image, label\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "def construct_dataset(ds):\n",
    "    ds = ds.shuffle(buffer_size=BATCH_SIZE)\n",
    "    \n",
    "#     ds=ds.repeat()\n",
    "    ds = ds.batch(BATCH_SIZE, drop_remainder=False)\n",
    "#     ds = ds.map(process_dataset,num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_data = construct_dataset(train_data)\n",
    "test_data = construct_dataset(test_data)\n",
    "\n",
    "steps_per_epoch=math.ceil(50000/BATCH_SIZE)\n",
    "validation_steps=math.ceil(10000/BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 15, 15, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 5, 5, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 225,354\n",
      "Trainable params: 224,714\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Activation\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "# dimensionality of input and latent encoded representations\n",
    "inpt_dim = (32, 32, 3)\n",
    "\n",
    "inpt_img = Input(shape=inpt_dim)\n",
    "\n",
    "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape = inpt_dim )(inpt_img)\n",
    "\n",
    "# Block 1\n",
    "cl1 = Conv2D(64, (3, 3), strides=(2, 2),activation='relu')(rescale)\n",
    "bnl2 = BatchNormalization()(cl1)\n",
    "# afl3 = Activation('relu')(bnl2)\n",
    "pl4 = MaxPooling2D(pool_size = (2, 2))(bnl2)\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "cl5 = Conv2D(128, (3, 3), strides=(1, 1), activation='relu')(pl4)\n",
    "bnl6 = BatchNormalization()(cl5)\n",
    "# afl7 = Activation('relu')(bnl6)\n",
    "pl8 = MaxPooling2D(pool_size = (2, 2))(bnl6)\n",
    "bnl9 = BatchNormalization()(pl8)\n",
    "\n",
    "# Step 3 - Flattening\n",
    "fl10 = Flatten()(bnl9)\n",
    "\n",
    "# Step 4 - Full connection\n",
    "dol11 = Dropout(0.5)(fl10)\n",
    "dl12 = Dense(units = 256, activation = 'relu')(dol11)\n",
    "dol13 = Dropout(0.2)(dl12)\n",
    "dl14 = Dense(units = 64, activation = 'relu')(dol13)\n",
    "dol15 = Dropout(0.1)(dl14)\n",
    "output = Dense(units = 10, activation = 'sigmoid')(dol15)\n",
    "\n",
    "classifier = Model(inpt_img, output)\n",
    "\n",
    "# Compiling the CNN\n",
    "opt = RMSprop(learning_rate=0.001)\n",
    "# opt = Adam(learning_rate=0.01)\n",
    "\n",
    "classifier.compile(optimizer = opt, loss ='binary_crossentropy', \n",
    "                   metrics = ['accuracy'])\n",
    "\n",
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 0.2688 - accuracy: 0.3814 - val_loss: 0.2800 - val_accuracy: 0.3137\n",
      "Epoch 2/1000\n",
      "500/500 [==============================] - 22s 44ms/step - loss: 0.2205 - accuracy: 0.5021 - val_loss: 0.2509 - val_accuracy: 0.4502\n",
      "Epoch 3/1000\n",
      "500/500 [==============================] - 23s 46ms/step - loss: 0.2025 - accuracy: 0.5524 - val_loss: 0.1920 - val_accuracy: 0.5741\n",
      "Epoch 4/1000\n",
      "500/500 [==============================] - 24s 47ms/step - loss: 0.1926 - accuracy: 0.5752 - val_loss: 0.2035 - val_accuracy: 0.5404\n",
      "Epoch 5/1000\n",
      "500/500 [==============================] - 23s 47ms/step - loss: 0.1843 - accuracy: 0.5983 - val_loss: 0.1957 - val_accuracy: 0.5588\n",
      "Epoch 6/1000\n",
      "500/500 [==============================] - 25s 50ms/step - loss: 0.1786 - accuracy: 0.6124 - val_loss: 0.1978 - val_accuracy: 0.5583\n",
      "Epoch 7/1000\n",
      "500/500 [==============================] - 25s 51ms/step - loss: 0.1738 - accuracy: 0.6263 - val_loss: 0.1949 - val_accuracy: 0.5670\n",
      "Epoch 8/1000\n",
      "500/500 [==============================] - 34s 67ms/step - loss: 0.1688 - accuracy: 0.6366 - val_loss: 0.1717 - val_accuracy: 0.6222\n",
      "Epoch 9/1000\n",
      "500/500 [==============================] - 36s 73ms/step - loss: 0.1656 - accuracy: 0.6447 - val_loss: 0.1921 - val_accuracy: 0.5727\n",
      "Epoch 10/1000\n",
      "500/500 [==============================] - 37s 74ms/step - loss: 0.1614 - accuracy: 0.6542 - val_loss: 0.1650 - val_accuracy: 0.6367\n",
      "Epoch 11/1000\n",
      "500/500 [==============================] - 30s 60ms/step - loss: 0.1586 - accuracy: 0.6625 - val_loss: 0.1623 - val_accuracy: 0.6430\n",
      "Epoch 12/1000\n",
      "500/500 [==============================] - 34s 68ms/step - loss: 0.1557 - accuracy: 0.6714 - val_loss: 0.1726 - val_accuracy: 0.6288\n",
      "Epoch 13/1000\n",
      "500/500 [==============================] - 34s 69ms/step - loss: 0.1523 - accuracy: 0.6770 - val_loss: 0.1735 - val_accuracy: 0.6235\n",
      "Epoch 14/1000\n",
      "500/500 [==============================] - 38s 77ms/step - loss: 0.1505 - accuracy: 0.6820 - val_loss: 0.1871 - val_accuracy: 0.5922\n",
      "Epoch 15/1000\n",
      "500/500 [==============================] - 40s 80ms/step - loss: 0.1492 - accuracy: 0.6865 - val_loss: 0.1533 - val_accuracy: 0.6720\n",
      "Epoch 16/1000\n",
      "500/500 [==============================] - 40s 79ms/step - loss: 0.1469 - accuracy: 0.6909 - val_loss: 0.1534 - val_accuracy: 0.6635\n",
      "Epoch 17/1000\n",
      "500/500 [==============================] - 38s 76ms/step - loss: 0.1448 - accuracy: 0.6940 - val_loss: 0.1545 - val_accuracy: 0.6678\n",
      "Epoch 18/1000\n",
      "500/500 [==============================] - 49s 98ms/step - loss: 0.1434 - accuracy: 0.6990 - val_loss: 0.1535 - val_accuracy: 0.6696\n",
      "Epoch 19/1000\n",
      "500/500 [==============================] - 49s 99ms/step - loss: 0.1423 - accuracy: 0.7021 - val_loss: 0.1482 - val_accuracy: 0.6898\n",
      "Epoch 20/1000\n",
      "500/500 [==============================] - 51s 103ms/step - loss: 0.1402 - accuracy: 0.7065 - val_loss: 0.1626 - val_accuracy: 0.6524\n",
      "Epoch 21/1000\n",
      "500/500 [==============================] - 49s 98ms/step - loss: 0.1384 - accuracy: 0.7099 - val_loss: 0.1435 - val_accuracy: 0.6969\n",
      "Epoch 22/1000\n",
      "500/500 [==============================] - 51s 102ms/step - loss: 0.1381 - accuracy: 0.7121 - val_loss: 0.1482 - val_accuracy: 0.6870\n",
      "Epoch 23/1000\n",
      "500/500 [==============================] - 50s 99ms/step - loss: 0.1368 - accuracy: 0.7153 - val_loss: 0.1435 - val_accuracy: 0.6956\n",
      "Epoch 24/1000\n",
      "500/500 [==============================] - 51s 102ms/step - loss: 0.1361 - accuracy: 0.7178 - val_loss: 0.1402 - val_accuracy: 0.7078\n",
      "Epoch 25/1000\n",
      "500/500 [==============================] - 53s 107ms/step - loss: 0.1338 - accuracy: 0.7215 - val_loss: 0.1512 - val_accuracy: 0.6804\n",
      "Epoch 26/1000\n",
      "500/500 [==============================] - 64s 128ms/step - loss: 0.1333 - accuracy: 0.7234 - val_loss: 0.1431 - val_accuracy: 0.6960\n",
      "Epoch 27/1000\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 0.1321 - accuracy: 0.7232 - val_loss: 0.1390 - val_accuracy: 0.7052\n",
      "Epoch 28/1000\n",
      "500/500 [==============================] - 64s 128ms/step - loss: 0.1319 - accuracy: 0.7277 - val_loss: 0.1517 - val_accuracy: 0.6728\n",
      "Epoch 29/1000\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 0.1301 - accuracy: 0.7305 - val_loss: 0.1490 - val_accuracy: 0.6784\n",
      "Epoch 30/1000\n",
      "500/500 [==============================] - 56s 113ms/step - loss: 0.1296 - accuracy: 0.7322 - val_loss: 0.1558 - val_accuracy: 0.6635\n",
      "Epoch 31/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 0.1296 - accuracy: 0.7322 - val_loss: 0.1707 - val_accuracy: 0.6352\n",
      "Epoch 32/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.1285 - accuracy: 0.7365 - val_loss: 0.1396 - val_accuracy: 0.7013\n",
      "Epoch 33/1000\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 0.1267 - accuracy: 0.7387 - val_loss: 0.1791 - val_accuracy: 0.6190\n",
      "Epoch 34/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.1262 - accuracy: 0.7396 - val_loss: 0.1597 - val_accuracy: 0.6740\n",
      "Epoch 35/1000\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 0.1267 - accuracy: 0.7394 - val_loss: 0.1399 - val_accuracy: 0.7035\n",
      "Epoch 36/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.1252 - accuracy: 0.7420 - val_loss: 0.1514 - val_accuracy: 0.6719\n",
      "Epoch 37/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1239 - accuracy: 0.7441\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 0.1239 - accuracy: 0.7441 - val_loss: 0.1416 - val_accuracy: 0.6947\n",
      "Epoch 38/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.1163 - accuracy: 0.7616 - val_loss: 0.1357 - val_accuracy: 0.7127\n",
      "Epoch 39/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.1149 - accuracy: 0.7645 - val_loss: 0.1353 - val_accuracy: 0.7143\n",
      "Epoch 40/1000\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.1145 - accuracy: 0.7653 - val_loss: 0.1375 - val_accuracy: 0.7142\n",
      "Epoch 41/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 0.1118 - accuracy: 0.7713 - val_loss: 0.1343 - val_accuracy: 0.7209\n",
      "Epoch 42/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.1127 - accuracy: 0.7732 - val_loss: 0.1264 - val_accuracy: 0.7364\n",
      "Epoch 43/1000\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 0.1110 - accuracy: 0.7745 - val_loss: 0.1323 - val_accuracy: 0.7230\n",
      "Epoch 44/1000\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 0.1110 - accuracy: 0.7740 - val_loss: 0.1285 - val_accuracy: 0.7318\n",
      "Epoch 45/1000\n",
      "500/500 [==============================] - 64s 129ms/step - loss: 0.1109 - accuracy: 0.7755 - val_loss: 0.1323 - val_accuracy: 0.7201\n",
      "Epoch 46/1000\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 0.1092 - accuracy: 0.7782 - val_loss: 0.1304 - val_accuracy: 0.7273\n",
      "Epoch 47/1000\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 0.1094 - accuracy: 0.7773 - val_loss: 0.1299 - val_accuracy: 0.7332\n",
      "Epoch 48/1000\n",
      "500/500 [==============================] - 58s 115ms/step - loss: 0.1081 - accuracy: 0.7800 - val_loss: 0.1316 - val_accuracy: 0.7253\n",
      "Epoch 49/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.1083 - accuracy: 0.7793 - val_loss: 0.1335 - val_accuracy: 0.7287\n",
      "Epoch 50/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.1083 - accuracy: 0.7801 - val_loss: 0.1299 - val_accuracy: 0.7301\n",
      "Epoch 51/1000\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 0.1083 - accuracy: 0.7840 - val_loss: 0.1277 - val_accuracy: 0.7371\n",
      "Epoch 52/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.7829\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.1069 - accuracy: 0.7829 - val_loss: 0.1314 - val_accuracy: 0.7346\n",
      "Epoch 53/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.1034 - accuracy: 0.7922 - val_loss: 0.1299 - val_accuracy: 0.7329\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 62s 124ms/step - loss: 0.1020 - accuracy: 0.7936 - val_loss: 0.1265 - val_accuracy: 0.7367\n",
      "Epoch 55/1000\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 0.1020 - accuracy: 0.7930 - val_loss: 0.1259 - val_accuracy: 0.7403\n",
      "Epoch 56/1000\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 0.1005 - accuracy: 0.7977 - val_loss: 0.1257 - val_accuracy: 0.7419\n",
      "Epoch 57/1000\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.1014 - accuracy: 0.7937 - val_loss: 0.1251 - val_accuracy: 0.7423\n",
      "Epoch 58/1000\n",
      "500/500 [==============================] - 55s 111ms/step - loss: 0.1009 - accuracy: 0.7970 - val_loss: 0.1256 - val_accuracy: 0.7425\n",
      "Epoch 59/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 0.0999 - accuracy: 0.7983 - val_loss: 0.1268 - val_accuracy: 0.7368\n",
      "Epoch 60/1000\n",
      "500/500 [==============================] - 57s 114ms/step - loss: 0.1002 - accuracy: 0.7974 - val_loss: 0.1250 - val_accuracy: 0.7445\n",
      "Epoch 61/1000\n",
      "500/500 [==============================] - 55s 111ms/step - loss: 0.0995 - accuracy: 0.7994 - val_loss: 0.1334 - val_accuracy: 0.7277\n",
      "Epoch 62/1000\n",
      "500/500 [==============================] - 56s 113ms/step - loss: 0.1007 - accuracy: 0.7979 - val_loss: 0.1247 - val_accuracy: 0.7418\n",
      "Epoch 63/1000\n",
      "500/500 [==============================] - 58s 115ms/step - loss: 0.0985 - accuracy: 0.8013 - val_loss: 0.1257 - val_accuracy: 0.7468\n",
      "Epoch 64/1000\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.0987 - accuracy: 0.8011 - val_loss: 0.1248 - val_accuracy: 0.7424\n",
      "Epoch 65/1000\n",
      "500/500 [==============================] - 56s 113ms/step - loss: 0.0987 - accuracy: 0.8023 - val_loss: 0.1261 - val_accuracy: 0.7408\n",
      "Epoch 66/1000\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 0.0986 - accuracy: 0.8031 - val_loss: 0.1242 - val_accuracy: 0.7458\n",
      "Epoch 67/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 0.0981 - accuracy: 0.8008 - val_loss: 0.1269 - val_accuracy: 0.7372\n",
      "Epoch 68/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0975 - accuracy: 0.8045 - val_loss: 0.1270 - val_accuracy: 0.7381\n",
      "Epoch 69/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.0976 - accuracy: 0.8052 - val_loss: 0.1254 - val_accuracy: 0.7440\n",
      "Epoch 70/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0970 - accuracy: 0.8050 - val_loss: 0.1262 - val_accuracy: 0.7399\n",
      "Epoch 71/1000\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 0.0969 - accuracy: 0.8074 - val_loss: 0.1270 - val_accuracy: 0.7390\n",
      "Epoch 72/1000\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.0967 - accuracy: 0.8065 - val_loss: 0.1281 - val_accuracy: 0.7404\n",
      "Epoch 73/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.0974 - accuracy: 0.8046 - val_loss: 0.1236 - val_accuracy: 0.7469\n",
      "Epoch 74/1000\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 0.0962 - accuracy: 0.8070 - val_loss: 0.1253 - val_accuracy: 0.7460\n",
      "Epoch 75/1000\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.0957 - accuracy: 0.8077 - val_loss: 0.1326 - val_accuracy: 0.7262\n",
      "Epoch 76/1000\n",
      "500/500 [==============================] - 57s 113ms/step - loss: 0.0958 - accuracy: 0.8069 - val_loss: 0.1255 - val_accuracy: 0.7422\n",
      "Epoch 77/1000\n",
      "500/500 [==============================] - 56s 112ms/step - loss: 0.0965 - accuracy: 0.8075 - val_loss: 0.1279 - val_accuracy: 0.7393\n",
      "Epoch 78/1000\n",
      "500/500 [==============================] - 58s 115ms/step - loss: 0.0959 - accuracy: 0.8081 - val_loss: 0.1285 - val_accuracy: 0.7402\n",
      "Epoch 79/1000\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.0951 - accuracy: 0.8097 - val_loss: 0.1285 - val_accuracy: 0.7362\n",
      "Epoch 80/1000\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 0.0958 - accuracy: 0.8072 - val_loss: 0.1251 - val_accuracy: 0.7482\n",
      "Epoch 81/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.0952 - accuracy: 0.8098 - val_loss: 0.1286 - val_accuracy: 0.7441\n",
      "Epoch 82/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.0952 - accuracy: 0.8103 - val_loss: 0.1246 - val_accuracy: 0.7469\n",
      "Epoch 83/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.8107\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 0.0945 - accuracy: 0.8107 - val_loss: 0.1303 - val_accuracy: 0.7339\n",
      "Epoch 84/1000\n",
      "500/500 [==============================] - 56s 112ms/step - loss: 0.0923 - accuracy: 0.8151 - val_loss: 0.1254 - val_accuracy: 0.7454\n",
      "Epoch 85/1000\n",
      "500/500 [==============================] - 56s 112ms/step - loss: 0.0927 - accuracy: 0.8133 - val_loss: 0.1283 - val_accuracy: 0.7468\n",
      "Epoch 86/1000\n",
      "500/500 [==============================] - 56s 111ms/step - loss: 0.0927 - accuracy: 0.8151 - val_loss: 0.1251 - val_accuracy: 0.7486\n",
      "Epoch 87/1000\n",
      "500/500 [==============================] - 56s 111ms/step - loss: 0.0915 - accuracy: 0.8180 - val_loss: 0.1231 - val_accuracy: 0.7494\n",
      "Epoch 88/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.0925 - accuracy: 0.8160 - val_loss: 0.1259 - val_accuracy: 0.7468\n",
      "Epoch 89/1000\n",
      "500/500 [==============================] - 57s 114ms/step - loss: 0.0910 - accuracy: 0.8193 - val_loss: 0.1256 - val_accuracy: 0.7488\n",
      "Epoch 90/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.0910 - accuracy: 0.8165 - val_loss: 0.1256 - val_accuracy: 0.7485\n",
      "Epoch 91/1000\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.0924 - accuracy: 0.8156 - val_loss: 0.1253 - val_accuracy: 0.7457\n",
      "Epoch 92/1000\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 0.0908 - accuracy: 0.8206 - val_loss: 0.1262 - val_accuracy: 0.7471\n",
      "Epoch 93/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 0.0901 - accuracy: 0.8192 - val_loss: 0.1256 - val_accuracy: 0.7479\n",
      "Epoch 94/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0907 - accuracy: 0.8196 - val_loss: 0.1244 - val_accuracy: 0.7525\n",
      "Epoch 95/1000\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 0.0901 - accuracy: 0.8203 - val_loss: 0.1259 - val_accuracy: 0.7449\n",
      "Epoch 96/1000\n",
      "500/500 [==============================] - 57s 115ms/step - loss: 0.0909 - accuracy: 0.8178 - val_loss: 0.1267 - val_accuracy: 0.7449\n",
      "Epoch 97/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.8176\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "500/500 [==============================] - 57s 114ms/step - loss: 0.0915 - accuracy: 0.8176 - val_loss: 0.1255 - val_accuracy: 0.7464\n",
      "Epoch 98/1000\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 0.0899 - accuracy: 0.8221 - val_loss: 0.1242 - val_accuracy: 0.7486\n",
      "Epoch 99/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0898 - accuracy: 0.8217 - val_loss: 0.1247 - val_accuracy: 0.7500\n",
      "Epoch 100/1000\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 0.0885 - accuracy: 0.8240 - val_loss: 0.1244 - val_accuracy: 0.7512\n",
      "Epoch 101/1000\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 0.0892 - accuracy: 0.8219 - val_loss: 0.1255 - val_accuracy: 0.7524\n",
      "Epoch 102/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0893 - accuracy: 0.8229 - val_loss: 0.1243 - val_accuracy: 0.7524\n",
      "Epoch 103/1000\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 0.0886 - accuracy: 0.8241 - val_loss: 0.1249 - val_accuracy: 0.7531\n",
      "Epoch 104/1000\n",
      "500/500 [==============================] - 57s 115ms/step - loss: 0.0885 - accuracy: 0.8231 - val_loss: 0.1241 - val_accuracy: 0.7503\n",
      "Epoch 105/1000\n",
      "500/500 [==============================] - 55s 110ms/step - loss: 0.0892 - accuracy: 0.8236 - val_loss: 0.1241 - val_accuracy: 0.7499\n",
      "Epoch 106/1000\n",
      "500/500 [==============================] - 56s 112ms/step - loss: 0.0889 - accuracy: 0.8234 - val_loss: 0.1249 - val_accuracy: 0.7496\n",
      "Epoch 107/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.8248\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 0.0883 - accuracy: 0.8248 - val_loss: 0.1235 - val_accuracy: 0.7526\n",
      "Epoch 108/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.0878 - accuracy: 0.8252 - val_loss: 0.1234 - val_accuracy: 0.7517\n",
      "Epoch 109/1000\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 0.0879 - accuracy: 0.8255 - val_loss: 0.1242 - val_accuracy: 0.7531\n",
      "Epoch 110/1000\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 0.0888 - accuracy: 0.8248 - val_loss: 0.1232 - val_accuracy: 0.7521\n",
      "Epoch 111/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0875 - accuracy: 0.8240 - val_loss: 0.1240 - val_accuracy: 0.7536\n",
      "Epoch 112/1000\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.0880 - accuracy: 0.8243 - val_loss: 0.1235 - val_accuracy: 0.7537\n",
      "Epoch 113/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 0.0876 - accuracy: 0.8270 - val_loss: 0.1237 - val_accuracy: 0.7523\n",
      "Epoch 114/1000\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 0.0879 - accuracy: 0.8248 - val_loss: 0.1244 - val_accuracy: 0.7506\n",
      "Epoch 115/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.0873 - accuracy: 0.8272 - val_loss: 0.1237 - val_accuracy: 0.7501\n",
      "Epoch 116/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0867 - accuracy: 0.8281 - val_loss: 0.1229 - val_accuracy: 0.7542\n",
      "Epoch 117/1000\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 0.0866 - accuracy: 0.8289 - val_loss: 0.1237 - val_accuracy: 0.7551\n",
      "Epoch 118/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0874 - accuracy: 0.8282 - val_loss: 0.1233 - val_accuracy: 0.7529\n",
      "Epoch 119/1000\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 0.0884 - accuracy: 0.8252 - val_loss: 0.1242 - val_accuracy: 0.7533\n",
      "Epoch 120/1000\n",
      "500/500 [==============================] - 55s 110ms/step - loss: 0.0873 - accuracy: 0.8263 - val_loss: 0.1235 - val_accuracy: 0.7533\n",
      "Epoch 121/1000\n",
      "500/500 [==============================] - 55s 110ms/step - loss: 0.0873 - accuracy: 0.8254 - val_loss: 0.1241 - val_accuracy: 0.7506\n",
      "Epoch 122/1000\n",
      "500/500 [==============================] - 56s 111ms/step - loss: 0.0876 - accuracy: 0.8274 - val_loss: 0.1236 - val_accuracy: 0.7526\n",
      "Epoch 123/1000\n",
      "500/500 [==============================] - 57s 114ms/step - loss: 0.0880 - accuracy: 0.8252 - val_loss: 0.1236 - val_accuracy: 0.7518\n",
      "Epoch 124/1000\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 0.0870 - accuracy: 0.8286 - val_loss: 0.1245 - val_accuracy: 0.7518\n",
      "Epoch 125/1000\n",
      "500/500 [==============================] - 57s 114ms/step - loss: 0.0873 - accuracy: 0.8270 - val_loss: 0.1232 - val_accuracy: 0.7533\n",
      "Epoch 126/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.8257\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 0.0872 - accuracy: 0.8257 - val_loss: 0.1239 - val_accuracy: 0.7513\n",
      "Epoch 127/1000\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 0.0880 - accuracy: 0.8259 - val_loss: 0.1233 - val_accuracy: 0.7539\n",
      "Epoch 128/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0864 - accuracy: 0.8278 - val_loss: 0.1237 - val_accuracy: 0.7540\n",
      "Epoch 129/1000\n",
      "500/500 [==============================] - 57s 114ms/step - loss: 0.0876 - accuracy: 0.8255 - val_loss: 0.1232 - val_accuracy: 0.7527\n",
      "Epoch 130/1000\n",
      "500/500 [==============================] - 57s 113ms/step - loss: 0.0878 - accuracy: 0.8266 - val_loss: 0.1234 - val_accuracy: 0.7529\n",
      "Epoch 131/1000\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.0873 - accuracy: 0.8295 - val_loss: 0.1236 - val_accuracy: 0.7542\n",
      "Epoch 132/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0879 - accuracy: 0.8277 - val_loss: 0.1234 - val_accuracy: 0.7536\n",
      "Epoch 133/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 0.0869 - accuracy: 0.8289 - val_loss: 0.1233 - val_accuracy: 0.7544\n",
      "Epoch 134/1000\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 0.0876 - accuracy: 0.8262 - val_loss: 0.1232 - val_accuracy: 0.7537\n",
      "Epoch 135/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 0.0871 - accuracy: 0.8272 - val_loss: 0.1230 - val_accuracy: 0.7551\n",
      "Epoch 136/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.8283\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 0.0864 - accuracy: 0.8283 - val_loss: 0.1233 - val_accuracy: 0.7530\n",
      "Epoch 137/1000\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 0.0872 - accuracy: 0.8283 - val_loss: 0.1231 - val_accuracy: 0.7530\n",
      "Epoch 138/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0861 - accuracy: 0.8284 - val_loss: 0.1230 - val_accuracy: 0.7551\n",
      "Epoch 139/1000\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 0.0866 - accuracy: 0.8282 - val_loss: 0.1230 - val_accuracy: 0.7540\n",
      "Epoch 140/1000\n",
      "500/500 [==============================] - 57s 115ms/step - loss: 0.0865 - accuracy: 0.8271 - val_loss: 0.1231 - val_accuracy: 0.7543\n",
      "Epoch 141/1000\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 0.0870 - accuracy: 0.8276 - val_loss: 0.1232 - val_accuracy: 0.7537\n",
      "Epoch 142/1000\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 0.0866 - accuracy: 0.8276 - val_loss: 0.1230 - val_accuracy: 0.7542\n",
      "Epoch 143/1000\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.0869 - accuracy: 0.8269 - val_loss: 0.1232 - val_accuracy: 0.7542\n",
      "Epoch 144/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 0.0874 - accuracy: 0.8265 - val_loss: 0.1232 - val_accuracy: 0.7534\n",
      "Epoch 145/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 0.0860 - accuracy: 0.8281 - val_loss: 0.1230 - val_accuracy: 0.7542\n",
      "Epoch 146/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.8296\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 0.0864 - accuracy: 0.8296 - val_loss: 0.1231 - val_accuracy: 0.7542\n",
      "Epoch 147/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 0.0868 - accuracy: 0.8284 - val_loss: 0.1231 - val_accuracy: 0.7545\n",
      "Epoch 148/1000\n",
      "500/500 [==============================] - 57s 114ms/step - loss: 0.0861 - accuracy: 0.8307 - val_loss: 0.1230 - val_accuracy: 0.7543\n",
      "Epoch 149/1000\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 0.0859 - accuracy: 0.8292 - val_loss: 0.1230 - val_accuracy: 0.7539\n",
      "Epoch 150/1000\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 0.0866 - accuracy: 0.8278 - val_loss: 0.1230 - val_accuracy: 0.7538\n",
      "Epoch 151/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.8277Restoring model weights from the end of the best epoch.\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 0.0869 - accuracy: 0.8277 - val_loss: 0.1232 - val_accuracy: 0.7532\n",
      "Epoch 00151: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fitting the CNN to the images\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10,  \n",
    "                              min_delta=1e-4, mode='min', verbose=1)\n",
    "\n",
    "stop_alg = EarlyStopping(monitor='val_loss', patience=35, \n",
    "                         restore_best_weights=True, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "hist = classifier.fit(train_data,  epochs=1000, \n",
    "                   callbacks=[stop_alg, reduce_lr], \n",
    "                      validation_steps=validation_steps,\n",
    "                      steps_per_epoch=steps_per_epoch,\n",
    "                   validation_data=test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
