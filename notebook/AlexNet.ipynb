{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
    "CLASS_NAMES= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "validation_images, validation_labels = train_images[:5000], train_labels[:5000]\n",
    "train_images, train_labels = train_images[5000:], train_labels[5000:]\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 45000\n",
      "Test data size: 10000\n",
      "Validation data size: 5000\n"
     ]
    }
   ],
   "source": [
    "def process_images(image, label):\n",
    "    # Normalize images to have a mean of 0 and standard deviation of 1\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    # Resize images from 32x32 to 277x277\n",
    "    image = tf.image.resize(image, (227,227))\n",
    "    return image, label\n",
    "\n",
    "train_ds_size = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "test_ds_size = tf.data.experimental.cardinality(test_ds).numpy()\n",
    "validation_ds_size = tf.data.experimental.cardinality(validation_ds).numpy()\n",
    "print(\"Training data size:\", train_ds_size)\n",
    "print(\"Test data size:\", test_ds_size)\n",
    "print(\"Validation data size:\", validation_ds_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = (train_ds\n",
    "                  .map(process_images)\n",
    "                  .shuffle(buffer_size=train_ds_size)\n",
    "                  .batch(batch_size=32, drop_remainder=True))\n",
    "test_ds = (test_ds\n",
    "                  .map(process_images)\n",
    "                  .shuffle(buffer_size=train_ds_size)\n",
    "                  .batch(batch_size=32, drop_remainder=True))\n",
    "validation_ds = (validation_ds\n",
    "                  .map(process_images)\n",
    "                  .shuffle(buffer_size=train_ds_size)\n",
    "                  .batch(batch_size=32, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 227, 227, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 55, 55, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 27, 384)       332160    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 27, 27, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 27, 27, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              177213440 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 196,615,690\n",
      "Trainable params: 196,615,498\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "1406/1406 [==============================] - 4181s 3s/step - loss: 57.0617 - accuracy: 0.0997 - val_loss: 57.4482 - val_accuracy: 0.1032\n",
      "Epoch 2/1000\n",
      "1406/1406 [==============================] - 4015s 3s/step - loss: 57.0956 - accuracy: 0.0996 - val_loss: 57.4482 - val_accuracy: 0.1040\n",
      "Epoch 3/1000\n",
      "1406/1406 [==============================] - 3941s 3s/step - loss: 57.1016 - accuracy: 0.0996 - val_loss: 57.4482 - val_accuracy: 0.1036\n",
      "Epoch 4/1000\n",
      "1406/1406 [==============================] - 3896s 3s/step - loss: 57.1003 - accuracy: 0.0996 - val_loss: 57.4853 - val_accuracy: 0.1038\n",
      "Epoch 5/1000\n",
      "1406/1406 [==============================] - 3833s 3s/step - loss: 57.0976 - accuracy: 0.0996 - val_loss: 57.4829 - val_accuracy: 0.1036\n",
      "Epoch 6/1000\n",
      "1406/1406 [==============================] - 3915s 3s/step - loss: 57.0940 - accuracy: 0.0996 - val_loss: 57.4309 - val_accuracy: 0.1040\n",
      "Epoch 7/1000\n",
      "1406/1406 [==============================] - 3924s 3s/step - loss: 57.0953 - accuracy: 0.0996 - val_loss: 57.4111 - val_accuracy: 0.1040\n",
      "Epoch 8/1000\n",
      "1406/1406 [==============================] - 3826s 3s/step - loss: 57.0948 - accuracy: 0.0995 - val_loss: 57.4705 - val_accuracy: 0.1038\n",
      "Epoch 9/1000\n",
      "1406/1406 [==============================] - 3880s 3s/step - loss: 57.0978 - accuracy: 0.0996 - val_loss: 57.4655 - val_accuracy: 0.1040\n",
      "Epoch 10/1000\n",
      "1406/1406 [==============================] - 3837s 3s/step - loss: 57.0993 - accuracy: 0.0996 - val_loss: 57.4630 - val_accuracy: 0.1040\n",
      "Epoch 11/1000\n",
      "1406/1406 [==============================] - 3968s 3s/step - loss: 57.0973 - accuracy: 0.0996 - val_loss: 57.4160 - val_accuracy: 0.1036\n",
      "Epoch 12/1000\n",
      "1406/1406 [==============================] - 3892s 3s/step - loss: 57.0995 - accuracy: 0.0996 - val_loss: 57.4804 - val_accuracy: 0.1038\n",
      "Epoch 13/1000\n",
      "1406/1406 [==============================] - 4043s 3s/step - loss: 57.0989 - accuracy: 0.0996 - val_loss: 57.4333 - val_accuracy: 0.1040\n",
      "Epoch 14/1000\n",
      "1406/1406 [==============================] - 3926s 3s/step - loss: 57.0997 - accuracy: 0.0996 - val_loss: 57.4135 - val_accuracy: 0.1040\n",
      "Epoch 15/1000\n",
      "1406/1406 [==============================] - 4002s 3s/step - loss: 57.1014 - accuracy: 0.0996 - val_loss: 57.4655 - val_accuracy: 0.1038\n",
      "Epoch 16/1000\n",
      "1312/1406 [==========================>...] - ETA: 4:18 - loss: 57.1323 - accuracy: 0.0997"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Activation\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "input_dim = (227, 227, 3)\n",
    "\n",
    "input_img = Input(shape=input_dim)\n",
    "\n",
    "# Layer 1\n",
    "cl1 = Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), padding='valid', activation='relu', \n",
    "             input_shape=input_dim)(input_img)\n",
    "bnl2 = BatchNormalization()(cl1)\n",
    "pl3 = MaxPooling2D(pool_size=(3, 3), strides=(2,2))(bnl2)\n",
    "\n",
    "# Layer 2\n",
    "cl4 = Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\")(pl3)\n",
    "bnl5 = BatchNormalization()(cl4)\n",
    "pl6 = MaxPooling2D(pool_size=(3, 3), strides=(2,2))(bnl5)\n",
    "\n",
    "# Layer 3\n",
    "cl7 = Conv2D(filters=384, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu')(pl3)\n",
    "\n",
    "# Layer 4\n",
    "cl8 = Conv2D(filters=384, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu')(cl7)\n",
    "\n",
    "# Layer 5\n",
    "cl9 = Conv2D(filters=256, kernel_size=(3,3), strides=(1, 1), padding='same', activation='relu')(cl8)\n",
    "pl10 = MaxPooling2D(pool_size=(3,3), strides=(2,2))(cl9)\n",
    "\n",
    "# Layer 6\n",
    "fl11 = Flatten()(pl10)\n",
    "dl12 = Dense(4096, activation='relu')(fl11)\n",
    "dol13 = Dropout(0.5)(dl12)\n",
    "dl14 = Dense(4096, activation='relu')(dol13)\n",
    "dol15 = Dropout(0.5)(dl14)\n",
    "output = Dense(units=10, activation = 'softmax')(dol15)\n",
    "\n",
    "classifier = Model(input_img, output)\n",
    "opt = RMSprop(learning_rate=0.001)\n",
    "# opt = Adam(learning_rate=0.01)\n",
    "\n",
    "\n",
    "classifier.compile(optimizer = opt, loss = 'binary_crossentropy', \n",
    "                   metrics = ['accuracy'])\n",
    "\n",
    "print(classifier.summary())# Fitting the CNN to the images\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10,  \n",
    "                              min_delta=1e-4, mode='min', verbose=1)\n",
    "\n",
    "stop_alg = EarlyStopping(monitor='val_loss', patience=35, \n",
    "                         restore_best_weights=True, verbose=1)\n",
    "\n",
    "hist = classifier.fit(train_ds, batch_size=100, epochs=1000, \n",
    "                   callbacks=[stop_alg, reduce_lr], shuffle=True, \n",
    "                   validation_data=validation_ds,\n",
    "                     validation_freq=1)\n",
    "\n",
    "classifier.save_weights(\"alexnet.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
