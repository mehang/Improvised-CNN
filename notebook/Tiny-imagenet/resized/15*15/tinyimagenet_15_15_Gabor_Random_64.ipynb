{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tinyimagenet-15*15-Gabor-Random-64.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPP1N0vIdFsa+VEPmxMBFpV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehang/Improvised-CNN/blob/master/notebook/Tiny-imagenet/resized/15*15/tinyimagenet_15_15_Gabor_Random_64.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1SqgORvk7R3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrqhS7yWnn1c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pathlib\n",
        "import time\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EbaDdzBnny3"
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/Mehang\\ Rai/tiny-imagenet.zip -d tiny-imagenet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtJDJ0eNnnwi"
      },
      "source": [
        "ITERATION = 1\n",
        "IMAGE_WIDTH=64\n",
        "IMAGE_HEIGHT=64\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3\n",
        "RANDOM_SEED = [42,42,34,56,62,74,29,15,7,81][ITERATION-1]\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 200\n",
        "EPOCHS = 1000\n",
        "GABOR_LAYER_INDEX = 0\n",
        "GABOR_WIDTH = 15\n",
        "GABOR_HEIGHT = 15\n",
        "GABOR_SIZE = (GABOR_WIDTH, GABOR_HEIGHT)\n",
        "NUM_RECEPTIVE_FILTERS = 32\n",
        "TRAIN_DIR = \"tiny-imagenet/tiny-imagenet/train/\"\n",
        "TEST_DIR = \"tiny-imagenet/tiny-imagenet/test/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mac1rS3snnt9"
      },
      "source": [
        "filenames = os.listdir(TRAIN_DIR)\n",
        "categories = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    categories.append(category)\n",
        "\n",
        "train_df = pd.DataFrame({\n",
        "    'filename': filenames,\n",
        "    'category': categories\n",
        "})\n",
        "\n",
        "filenames = os.listdir(TEST_DIR)\n",
        "categories = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    categories.append(category)\n",
        "\n",
        "validate_df = pd.DataFrame({\n",
        "    'filename': filenames,\n",
        "    'category': categories\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfwkRvVunnsa"
      },
      "source": [
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)\n",
        "total_train = train_df.shape[0]\n",
        "total_validate = validate_df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnmEGQ6bnnqF"
      },
      "source": [
        "train_df['category'].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chmh09_innn_"
      },
      "source": [
        "validate_df['category'].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4Ug5VNannld"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=45,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rescale=1./255,\n",
        ")\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df, \n",
        "    TRAIN_DIR, \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwz4IpCCnnjG"
      },
      "source": [
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    validate_df, \n",
        "    TEST_DIR, \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-EPkLOrnner"
      },
      "source": [
        "print(train_df.shape)\n",
        "print(validate_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umgJ_7gDnncP"
      },
      "source": [
        "train_generator.image_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL3itLdvnnZ4"
      },
      "source": [
        "NUM_CLASSES = len(train_df['category'].value_counts())\n",
        "print(NUM_CLASSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tWE-U-qnnXj"
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Activation\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "classifier = None\n",
        "classifier = Sequential([\n",
        "    layers.Conv2D(NUM_RECEPTIVE_FILTERS, kernel_size=GABOR_SIZE, strides=(1,1), padding='same', name=\"GaborLayer\", input_shape=train_generator.image_shape),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.Dropout(0.1),\n",
        "    layers.Conv2D(64, kernel_size=(3,3), padding='same', strides=(1,1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Conv2D(64, kernel_size=(3,3), padding='same', strides=(1,1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.Dropout(0.1),\n",
        "    layers.Conv2D(128, kernel_size=(3,3), padding='same', strides=(1,1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Conv2D(128, kernel_size=(3,3), padding='same', strides=(1,1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        layers.Conv2D(128, kernel_size=(3,3), padding='same', strides=(1,1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Dropout(0.1),\n",
        "    layers.Conv2D(256, kernel_size=(3,3), padding='same', strides=(1,1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "        layers.Conv2D(256, kernel_size=(3,3), padding='same', strides=(1,1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "        layers.Conv2D(256, kernel_size=(3,3), padding='same', strides=(1,1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.1),\n",
        "    layers.Dense(512),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Dropout(0.1),\n",
        "    layers.Dense(512),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "classifier.summary()\n",
        "\n",
        "import copy\n",
        "untrained_layers = copy.deepcopy(classifier.get_layer(name=classifier.layers[GABOR_LAYER_INDEX].name).get_weights())\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10,  \n",
        "                              min_delta=1e-4, mode='min', verbose=1)\n",
        "stop_alg = EarlyStopping(monitor='val_loss', patience=35, \n",
        "                         restore_best_weights=True, verbose=1)\n",
        "callbacks = [stop_alg, reduce_lr]\n",
        "opt = Adam(learning_rate=0.001)\n",
        "classifier.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', 'AUC'])\n",
        "\n",
        "start = time.perf_counter()\n",
        "hist = classifier.fit(\n",
        "    train_generator, \n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_validate//BATCH_SIZE,\n",
        "    steps_per_epoch=total_train//BATCH_SIZE,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "finish = time.perf_counter()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.plot(hist.history['loss'], color='#785ef0')\n",
        "plt.plot(hist.history['val_loss'], color='#dc267f')\n",
        "plt.title('Model Loss Progress')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Set', 'Test Set'], loc='upper right')\n",
        "# plt.savefig('stanfordcars-{}-loss-kernel-{}.png'.format(ITERATION,GABOR_WIDTH), dpi=350, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.plot(hist.history['accuracy'], color='#785ef0')\n",
        "plt.plot(hist.history['val_accuracy'], color='#dc267f')\n",
        "plt.title('Model Accuracy Progress')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Set', 'Test Set'], loc='upper right')\n",
        "# plt.savefig('stanfordcars-{}-accuracy-kernel-{}.png'.format(ITERATION, GABOR_WIDTH), dpi=350, bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkCOXHchnnVQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3636VbKennSq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs28bsCynnPx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdqd3Jd4nnNy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}