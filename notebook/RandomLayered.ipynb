{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "\n",
    "x_train, _, y_train, _ = train_test_split(x_train,y_train, train_size=0.5, stratify=y_train)\n",
    "x_test, _, y_test, _ = train_test_split(x_test, y_test, test_size=0.5, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = (32,32,3)\n",
    "input_img = Input(shape=input_dim)\n",
    "\n",
    "cl1_template = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same',\n",
    "             input_shape=input_dim, activation='relu')\n",
    "cl1 = cl1_template(input_img)\n",
    "pl1 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(cl1)\n",
    "\n",
    "cl2 = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same',\n",
    "             activation='relu')(pl1)\n",
    "pl2 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(cl2)\n",
    "\n",
    "cl3 = Conv2D(256, kernel_size=(3,3), strides=(1,1), padding='same',\n",
    "             activation='relu')(pl2)\n",
    "pl3 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(cl3)\n",
    "\n",
    "cl4 = Conv2D(512, kernel_size=(3,3), strides=(1,1), padding='same',\n",
    "             activation='relu')(pl3)\n",
    "pl4 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(cl4)\n",
    "\n",
    "cl5 = Conv2D(512, kernel_size=(3,3), strides=(1,1), padding='same',\n",
    "             activation='relu')(pl4)\n",
    "pl5 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(cl5)\n",
    "\n",
    "flat = Flatten()(pl5)\n",
    "\n",
    "fc6 = Dense(units=4096, activation='relu')(flat)\n",
    "fc7 = Dense(units=4096, activation='relu')(fc6)\n",
    "\n",
    "output = Dense(units=10, activation='softmax')(fc7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 22,834,314\n",
      "Trainable params: 22,834,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "250/250 [==============================] - 253s 1s/step - loss: 0.3312 - accuracy: 0.1488 - val_loss: 0.3086 - val_accuracy: 0.1728\n",
      "Epoch 2/1000\n",
      "250/250 [==============================] - 249s 997ms/step - loss: 0.2670 - accuracy: 0.3144 - val_loss: 0.2540 - val_accuracy: 0.3512\n",
      "Epoch 3/1000\n",
      "250/250 [==============================] - 251s 1s/step - loss: 0.2305 - accuracy: 0.4519 - val_loss: 0.2163 - val_accuracy: 0.4972\n",
      "Epoch 4/1000\n",
      "250/250 [==============================] - 245s 980ms/step - loss: 0.1987 - accuracy: 0.5405 - val_loss: 0.1888 - val_accuracy: 0.5698\n",
      "Epoch 5/1000\n",
      "250/250 [==============================] - 248s 993ms/step - loss: 0.1720 - accuracy: 0.6196 - val_loss: 0.1826 - val_accuracy: 0.6190\n",
      "Epoch 6/1000\n",
      "250/250 [==============================] - 249s 995ms/step - loss: 0.1499 - accuracy: 0.6754 - val_loss: 0.1733 - val_accuracy: 0.6454\n",
      "Epoch 7/1000\n",
      "250/250 [==============================] - 253s 1s/step - loss: 0.1332 - accuracy: 0.7167 - val_loss: 0.2591 - val_accuracy: 0.5422\n",
      "Epoch 8/1000\n",
      "250/250 [==============================] - 249s 995ms/step - loss: 0.1150 - accuracy: 0.7588 - val_loss: 0.1715 - val_accuracy: 0.6710\n",
      "Epoch 9/1000\n",
      "250/250 [==============================] - 253s 1s/step - loss: 0.1043 - accuracy: 0.7863 - val_loss: 0.1736 - val_accuracy: 0.6616\n",
      "Epoch 10/1000\n",
      "250/250 [==============================] - 251s 1s/step - loss: 0.0913 - accuracy: 0.8174 - val_loss: 0.1577 - val_accuracy: 0.6944\n",
      "Epoch 11/1000\n",
      "250/250 [==============================] - 246s 983ms/step - loss: 0.0791 - accuracy: 0.8452 - val_loss: 0.1657 - val_accuracy: 0.6966\n",
      "Epoch 12/1000\n",
      "250/250 [==============================] - 251s 1s/step - loss: 0.0695 - accuracy: 0.8686 - val_loss: 0.1730 - val_accuracy: 0.6926\n",
      "Epoch 13/1000\n",
      "250/250 [==============================] - 255s 1s/step - loss: 0.0617 - accuracy: 0.8850 - val_loss: 0.2072 - val_accuracy: 0.6750\n",
      "Epoch 14/1000\n",
      "250/250 [==============================] - 241s 964ms/step - loss: 0.0565 - accuracy: 0.8956 - val_loss: 0.1971 - val_accuracy: 0.6964\n",
      "Epoch 15/1000\n",
      "250/250 [==============================] - 232s 928ms/step - loss: 0.0505 - accuracy: 0.9080 - val_loss: 0.3341 - val_accuracy: 0.6880\n",
      "Epoch 16/1000\n",
      "250/250 [==============================] - 230s 922ms/step - loss: 0.0486 - accuracy: 0.9124 - val_loss: 0.2614 - val_accuracy: 0.6578\n",
      "Epoch 17/1000\n",
      "250/250 [==============================] - 227s 910ms/step - loss: 0.0425 - accuracy: 0.9228 - val_loss: 0.2140 - val_accuracy: 0.6838\n",
      "Epoch 18/1000\n",
      "250/250 [==============================] - 213s 852ms/step - loss: 0.0393 - accuracy: 0.9326 - val_loss: 0.2676 - val_accuracy: 0.6512\n",
      "Epoch 19/1000\n",
      "250/250 [==============================] - 213s 852ms/step - loss: 0.0384 - accuracy: 0.9344 - val_loss: 0.2569 - val_accuracy: 0.6684\n",
      "Epoch 20/1000\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9400\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "250/250 [==============================] - 233s 934ms/step - loss: 0.0355 - accuracy: 0.9400 - val_loss: 0.2756 - val_accuracy: 0.6944\n",
      "Epoch 21/1000\n",
      "250/250 [==============================] - 225s 900ms/step - loss: 0.0112 - accuracy: 0.9810 - val_loss: 0.3438 - val_accuracy: 0.7144\n",
      "Epoch 22/1000\n",
      "250/250 [==============================] - 217s 869ms/step - loss: 0.0097 - accuracy: 0.9858 - val_loss: 0.3722 - val_accuracy: 0.6852\n",
      "Epoch 23/1000\n",
      "250/250 [==============================] - 212s 849ms/step - loss: 0.0091 - accuracy: 0.9870 - val_loss: 0.3753 - val_accuracy: 0.7130\n",
      "Epoch 24/1000\n",
      "250/250 [==============================] - 216s 864ms/step - loss: 0.0110 - accuracy: 0.9853 - val_loss: 0.3517 - val_accuracy: 0.6972\n",
      "Epoch 25/1000\n",
      "250/250 [==============================] - 225s 900ms/step - loss: 0.0092 - accuracy: 0.9863 - val_loss: 0.3855 - val_accuracy: 0.7046\n",
      "Epoch 26/1000\n",
      "  7/250 [..............................] - ETA: 3:30 - loss: 0.0102 - accuracy: 0.9900"
     ]
    }
   ],
   "source": [
    "classifier = Model(input_img, output)\n",
    "\n",
    "opt = RMSprop(learning_rate=0.001)\n",
    "classifier.compile(optimizer=opt, loss ='binary_crossentropy',\n",
    "                   metrics = ['accuracy'])\n",
    "print(classifier.summary())\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=10, min_delta=1e-4,\n",
    "                              mode='min', verbose=1)\n",
    "stop_alg = EarlyStopping(monitor='val_loss', patience=35,\n",
    "                         restore_best_weights=True, verbose=1)\n",
    "\n",
    "hist = classifier.fit(x_train, y_train, batch_size=100,\n",
    "                      epochs=1000, callbacks=[stop_alg, reduce_lr],\n",
    "                      shuffle=True, validation_data=(x_test, y_test))\n",
    "classifier.save_weights(\"cnn.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
