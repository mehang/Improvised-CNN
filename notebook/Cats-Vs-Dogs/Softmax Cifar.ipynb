{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gabor_kernel\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "x_test shape: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import math\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 100\n",
    "IMAGE_SIZE = 32\n",
    "NUM_OF_CLASSES = 10\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# x_train = x_train.astype('float32') / 255.0\n",
    "# x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# y_train = to_categorical(y_train, 10)\n",
    "# y_test = to_categorical(y_test, 10)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 100\n",
    "IMAGE_SIZE = 32\n",
    "NUM_OF_CLASSES = 10\n",
    "\n",
    "def process_dataset(image, label):\n",
    "    # Normalize images to have a mean of 0 and standard deviation of 1\n",
    "#     image = tf.image.per_image_standardization(image)\n",
    "    \n",
    "#     image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # Resize images from 32x32 to 227x227\n",
    "#     image = tf.image.resize(image, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "\n",
    "#     image = image/255.0\n",
    "         \n",
    "    label = tf.one_hot(tf.cast(label, tf.int32), NUM_OF_CLASSES)\n",
    "        \n",
    "    return image, label\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "def construct_dataset(ds):\n",
    "    ds = ds.shuffle(buffer_size=BATCH_SIZE)\n",
    "    \n",
    "#     ds=ds.repeat()\n",
    "    ds = ds.batch(BATCH_SIZE, drop_remainder=False)\n",
    "#     ds = ds.map(process_dataset,num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_data = construct_dataset(train_data)\n",
    "test_data = construct_dataset(test_data)\n",
    "\n",
    "steps_per_epoch=math.ceil(50000/BATCH_SIZE)\n",
    "validation_steps=math.ceil(10000/BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 15, 15, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 5, 5, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 5, 5, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 225,354\n",
      "Trainable params: 224,714\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Activation\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "# dimensionality of input and latent encoded representations\n",
    "inpt_dim = (32, 32, 3)\n",
    "\n",
    "inpt_img = Input(shape=inpt_dim)\n",
    "\n",
    "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape = inpt_dim )(inpt_img)\n",
    "\n",
    "# Block 1\n",
    "cl1 = Conv2D(64, (3, 3), strides=(2, 2),activation='relu')(rescale)\n",
    "bnl2 = BatchNormalization()(cl1)\n",
    "# afl3 = Activation('relu')(bnl2)\n",
    "pl4 = MaxPooling2D(pool_size = (2, 2))(bnl2)\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "cl5 = Conv2D(128, (3, 3), strides=(1, 1), activation='relu')(pl4)\n",
    "bnl6 = BatchNormalization()(cl5)\n",
    "# afl7 = Activation('relu')(bnl6)\n",
    "pl8 = MaxPooling2D(pool_size = (2, 2))(bnl6)\n",
    "bnl9 = BatchNormalization()(pl8)\n",
    "\n",
    "# Step 3 - Flattening\n",
    "fl10 = Flatten()(bnl9)\n",
    "\n",
    "# Step 4 - Full connection\n",
    "dol11 = Dropout(0.5)(fl10)\n",
    "dl12 = Dense(units = 256, activation = 'relu')(dol11)\n",
    "dol13 = Dropout(0.2)(dl12)\n",
    "dl14 = Dense(units = 64, activation = 'relu')(dol13)\n",
    "dol15 = Dropout(0.1)(dl14)\n",
    "output = Dense(units = 10, activation = 'softmax')(dol15)\n",
    "\n",
    "classifier = Model(inpt_img, output)\n",
    "\n",
    "# Compiling the CNN\n",
    "opt = RMSprop(learning_rate=0.001)\n",
    "# opt = Adam(learning_rate=0.01)\n",
    "\n",
    "classifier.compile(optimizer = opt, loss =tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "                   metrics = ['accuracy'])\n",
    "\n",
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "500/500 [==============================] - 40s 80ms/step - loss: 2.0749 - accuracy: 0.3793 - val_loss: 2.2210 - val_accuracy: 0.2247\n",
      "Epoch 2/1000\n",
      "500/500 [==============================] - 42s 84ms/step - loss: 2.0023 - accuracy: 0.4529 - val_loss: 2.1252 - val_accuracy: 0.3286\n",
      "Epoch 3/1000\n",
      "500/500 [==============================] - 45s 89ms/step - loss: 1.9763 - accuracy: 0.4808 - val_loss: 2.0623 - val_accuracy: 0.3942\n",
      "Epoch 4/1000\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.9582 - accuracy: 0.4992 - val_loss: 2.0025 - val_accuracy: 0.4546\n",
      "Epoch 5/1000\n",
      "500/500 [==============================] - 48s 97ms/step - loss: 1.9525 - accuracy: 0.5053 - val_loss: 2.1389 - val_accuracy: 0.3176\n",
      "Epoch 6/1000\n",
      "500/500 [==============================] - 48s 97ms/step - loss: 1.9426 - accuracy: 0.5156 - val_loss: 1.9708 - val_accuracy: 0.4870\n",
      "Epoch 7/1000\n",
      "500/500 [==============================] - 48s 96ms/step - loss: 1.9391 - accuracy: 0.5190 - val_loss: 1.9738 - val_accuracy: 0.4846\n",
      "Epoch 8/1000\n",
      "500/500 [==============================] - 49s 97ms/step - loss: 1.9391 - accuracy: 0.5191 - val_loss: 2.1619 - val_accuracy: 0.2946\n",
      "Epoch 9/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 1.9307 - accuracy: 0.5271 - val_loss: 2.0319 - val_accuracy: 0.4265\n",
      "Epoch 10/1000\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 1.9278 - accuracy: 0.5304 - val_loss: 2.0905 - val_accuracy: 0.3683\n",
      "Epoch 11/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.9200 - accuracy: 0.5382 - val_loss: 1.9079 - val_accuracy: 0.5511\n",
      "Epoch 12/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.9205 - accuracy: 0.5378 - val_loss: 1.9560 - val_accuracy: 0.5041\n",
      "Epoch 13/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.9195 - accuracy: 0.5398 - val_loss: 1.9705 - val_accuracy: 0.4886\n",
      "Epoch 14/1000\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.9185 - accuracy: 0.5399 - val_loss: 1.9639 - val_accuracy: 0.4949\n",
      "Epoch 15/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.9175 - accuracy: 0.5410 - val_loss: 1.9794 - val_accuracy: 0.4799\n",
      "Epoch 16/1000\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 1.9112 - accuracy: 0.5477 - val_loss: 1.9854 - val_accuracy: 0.4741\n",
      "Epoch 17/1000\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 1.9071 - accuracy: 0.5518 - val_loss: 2.0056 - val_accuracy: 0.4541\n",
      "Epoch 18/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.9070 - accuracy: 0.5520 - val_loss: 1.9327 - val_accuracy: 0.5259\n",
      "Epoch 19/1000\n",
      "500/500 [==============================] - 64s 129ms/step - loss: 1.9034 - accuracy: 0.5562 - val_loss: 1.9695 - val_accuracy: 0.4900\n",
      "Epoch 20/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.9079 - accuracy: 0.5515 - val_loss: 1.9475 - val_accuracy: 0.5130\n",
      "Epoch 21/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.9041 - accuracy: 0.5553\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.9041 - accuracy: 0.5553 - val_loss: 1.9272 - val_accuracy: 0.5331\n",
      "Epoch 22/1000\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 1.8804 - accuracy: 0.5790 - val_loss: 1.9024 - val_accuracy: 0.5568\n",
      "Epoch 23/1000\n",
      "500/500 [==============================] - 58s 115ms/step - loss: 1.8756 - accuracy: 0.5842 - val_loss: 1.9023 - val_accuracy: 0.5580\n",
      "Epoch 24/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.8722 - accuracy: 0.5871 - val_loss: 1.8969 - val_accuracy: 0.5608\n",
      "Epoch 25/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.8632 - accuracy: 0.5965 - val_loss: 1.8768 - val_accuracy: 0.5817\n",
      "Epoch 26/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 1.8681 - accuracy: 0.5913 - val_loss: 1.8668 - val_accuracy: 0.5933\n",
      "Epoch 27/1000\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.8625 - accuracy: 0.5967 - val_loss: 1.8500 - val_accuracy: 0.6102\n",
      "Epoch 28/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.8554 - accuracy: 0.6040 - val_loss: 1.8936 - val_accuracy: 0.5657\n",
      "Epoch 29/1000\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 1.8600 - accuracy: 0.5993 - val_loss: 1.8958 - val_accuracy: 0.5641\n",
      "Epoch 30/1000\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 1.8548 - accuracy: 0.6049 - val_loss: 1.8566 - val_accuracy: 0.6023\n",
      "Epoch 31/1000\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 1.8562 - accuracy: 0.6032 - val_loss: 1.8740 - val_accuracy: 0.5854\n",
      "Epoch 32/1000\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.8534 - accuracy: 0.6056 - val_loss: 1.8709 - val_accuracy: 0.5898\n",
      "Epoch 33/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.8521 - accuracy: 0.6077 - val_loss: 1.8876 - val_accuracy: 0.5720\n",
      "Epoch 34/1000\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 1.8499 - accuracy: 0.6097 - val_loss: 1.9011 - val_accuracy: 0.5584\n",
      "Epoch 35/1000\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.8478 - accuracy: 0.6113 - val_loss: 1.8538 - val_accuracy: 0.6063\n",
      "Epoch 36/1000\n",
      "500/500 [==============================] - 64s 128ms/step - loss: 1.8449 - accuracy: 0.6148 - val_loss: 1.8677 - val_accuracy: 0.5914\n",
      "Epoch 37/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.8470 - accuracy: 0.6128\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 1.8470 - accuracy: 0.6128 - val_loss: 1.8974 - val_accuracy: 0.5617\n",
      "Epoch 38/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.8370 - accuracy: 0.6225 - val_loss: 1.8500 - val_accuracy: 0.6093\n",
      "Epoch 39/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 1.8361 - accuracy: 0.6233 - val_loss: 1.8452 - val_accuracy: 0.6146\n",
      "Epoch 40/1000\n",
      "500/500 [==============================] - 57s 114ms/step - loss: 1.8315 - accuracy: 0.6283 - val_loss: 1.8333 - val_accuracy: 0.6271\n",
      "Epoch 41/1000\n",
      "500/500 [==============================] - 57s 115ms/step - loss: 1.8302 - accuracy: 0.6296 - val_loss: 1.8292 - val_accuracy: 0.6301\n",
      "Epoch 42/1000\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 1.8283 - accuracy: 0.6311 - val_loss: 1.8295 - val_accuracy: 0.6297\n",
      "Epoch 43/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.8296 - accuracy: 0.6301 - val_loss: 1.8357 - val_accuracy: 0.6234\n",
      "Epoch 44/1000\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 1.8237 - accuracy: 0.6356 - val_loss: 1.8644 - val_accuracy: 0.5955\n",
      "Epoch 45/1000\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 1.8212 - accuracy: 0.6382 - val_loss: 1.8360 - val_accuracy: 0.6228\n",
      "Epoch 46/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.8220 - accuracy: 0.6376 - val_loss: 1.8152 - val_accuracy: 0.6446\n",
      "Epoch 47/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 1.8186 - accuracy: 0.6411 - val_loss: 1.8332 - val_accuracy: 0.6258\n",
      "Epoch 48/1000\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 1.8190 - accuracy: 0.6403 - val_loss: 1.8261 - val_accuracy: 0.6341\n",
      "Epoch 49/1000\n",
      "500/500 [==============================] - 58s 115ms/step - loss: 1.8181 - accuracy: 0.6415 - val_loss: 1.8153 - val_accuracy: 0.6434\n",
      "Epoch 50/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.8178 - accuracy: 0.6421 - val_loss: 1.8195 - val_accuracy: 0.6397\n",
      "Epoch 51/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 1.8153 - accuracy: 0.6440 - val_loss: 1.8374 - val_accuracy: 0.6225\n",
      "Epoch 52/1000\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 1.8165 - accuracy: 0.6429 - val_loss: 1.8197 - val_accuracy: 0.6403\n",
      "Epoch 53/1000\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 1.8140 - accuracy: 0.6456 - val_loss: 1.8603 - val_accuracy: 0.5991\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 63s 126ms/step - loss: 1.8117 - accuracy: 0.6484 - val_loss: 1.8231 - val_accuracy: 0.6357\n",
      "Epoch 55/1000\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 1.8139 - accuracy: 0.6451 - val_loss: 1.8128 - val_accuracy: 0.6467\n",
      "Epoch 56/1000\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 1.8087 - accuracy: 0.6512 - val_loss: 1.8175 - val_accuracy: 0.6420\n",
      "Epoch 57/1000\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 1.8100 - accuracy: 0.6498 - val_loss: 1.8102 - val_accuracy: 0.6488\n",
      "Epoch 58/1000\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 1.8099 - accuracy: 0.6496 - val_loss: 1.8254 - val_accuracy: 0.6337\n",
      "Epoch 59/1000\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 1.8072 - accuracy: 0.6525 - val_loss: 1.8172 - val_accuracy: 0.6428\n",
      "Epoch 60/1000\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 1.8077 - accuracy: 0.6519 - val_loss: 1.8355 - val_accuracy: 0.6248\n",
      "Epoch 61/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.8059 - accuracy: 0.6540 - val_loss: 1.8149 - val_accuracy: 0.6457\n",
      "Epoch 62/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 1.8035 - accuracy: 0.6563 - val_loss: 1.8147 - val_accuracy: 0.6453\n",
      "Epoch 63/1000\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 1.8069 - accuracy: 0.6524 - val_loss: 1.8289 - val_accuracy: 0.6293\n",
      "Epoch 64/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.8072 - accuracy: 0.6524 - val_loss: 1.8159 - val_accuracy: 0.6424\n",
      "Epoch 65/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.8049 - accuracy: 0.6547 - val_loss: 1.8138 - val_accuracy: 0.6458\n",
      "Epoch 66/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 1.8056 - accuracy: 0.6546 - val_loss: 1.8283 - val_accuracy: 0.6324\n",
      "Epoch 67/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.8051 - accuracy: 0.6548\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "500/500 [==============================] - 56s 113ms/step - loss: 1.8051 - accuracy: 0.6548 - val_loss: 1.8156 - val_accuracy: 0.6444\n",
      "Epoch 68/1000\n",
      "500/500 [==============================] - 56s 112ms/step - loss: 1.7992 - accuracy: 0.6605 - val_loss: 1.7988 - val_accuracy: 0.6609\n",
      "Epoch 69/1000\n",
      "500/500 [==============================] - 56s 112ms/step - loss: 1.7969 - accuracy: 0.6634 - val_loss: 1.8107 - val_accuracy: 0.6484\n",
      "Epoch 70/1000\n",
      "500/500 [==============================] - 57s 114ms/step - loss: 1.7977 - accuracy: 0.6619 - val_loss: 1.7977 - val_accuracy: 0.6623\n",
      "Epoch 71/1000\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 1.7969 - accuracy: 0.6624 - val_loss: 1.8098 - val_accuracy: 0.6497\n",
      "Epoch 72/1000\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 1.7934 - accuracy: 0.6661 - val_loss: 1.8028 - val_accuracy: 0.6571\n",
      "Epoch 73/1000\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 1.7945 - accuracy: 0.6649 - val_loss: 1.8007 - val_accuracy: 0.6596\n",
      "Epoch 74/1000\n",
      "500/500 [==============================] - 57s 115ms/step - loss: 1.7935 - accuracy: 0.6664 - val_loss: 1.7919 - val_accuracy: 0.6676\n",
      "Epoch 75/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 1.7903 - accuracy: 0.6697 - val_loss: 1.7932 - val_accuracy: 0.6665\n",
      "Epoch 76/1000\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 1.7915 - accuracy: 0.6688 - val_loss: 1.8051 - val_accuracy: 0.6542\n",
      "Epoch 77/1000\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 1.7910 - accuracy: 0.6687 - val_loss: 1.7887 - val_accuracy: 0.6715\n",
      "Epoch 78/1000\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 1.7930 - accuracy: 0.6673 - val_loss: 1.7954 - val_accuracy: 0.6633\n",
      "Epoch 79/1000\n",
      "500/500 [==============================] - 56s 112ms/step - loss: 1.7920 - accuracy: 0.6675 - val_loss: 1.7992 - val_accuracy: 0.6600\n",
      "Epoch 80/1000\n",
      "500/500 [==============================] - 57s 113ms/step - loss: 1.7895 - accuracy: 0.6700 - val_loss: 1.7930 - val_accuracy: 0.6652\n",
      "Epoch 81/1000\n",
      "500/500 [==============================] - 56s 112ms/step - loss: 1.7922 - accuracy: 0.6672 - val_loss: 1.7906 - val_accuracy: 0.6681\n",
      "Epoch 82/1000\n",
      "500/500 [==============================] - 57s 113ms/step - loss: 1.7894 - accuracy: 0.6702 - val_loss: 1.7986 - val_accuracy: 0.6597\n",
      "Epoch 83/1000\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 1.7871 - accuracy: 0.6724 - val_loss: 1.8073 - val_accuracy: 0.6523\n",
      "Epoch 84/1000\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 1.7889 - accuracy: 0.6710 - val_loss: 1.7893 - val_accuracy: 0.6702\n",
      "Epoch 85/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 1.7868 - accuracy: 0.6728 - val_loss: 1.7872 - val_accuracy: 0.6716\n",
      "Epoch 86/1000\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 1.7868 - accuracy: 0.6730 - val_loss: 1.7912 - val_accuracy: 0.6686\n",
      "Epoch 87/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7863 - accuracy: 0.6727 - val_loss: 1.7986 - val_accuracy: 0.6611\n",
      "Epoch 88/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 1.7899 - accuracy: 0.6697 - val_loss: 1.7887 - val_accuracy: 0.6699\n",
      "Epoch 89/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.7858 - accuracy: 0.6738 - val_loss: 1.8009 - val_accuracy: 0.6592\n",
      "Epoch 90/1000\n",
      "500/500 [==============================] - 62s 123ms/step - loss: 1.7849 - accuracy: 0.6750 - val_loss: 1.7875 - val_accuracy: 0.6708\n",
      "Epoch 91/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.7845 - accuracy: 0.6750 - val_loss: 1.7847 - val_accuracy: 0.6753\n",
      "Epoch 92/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7827 - accuracy: 0.6771 - val_loss: 1.7878 - val_accuracy: 0.6720\n",
      "Epoch 93/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 1.7832 - accuracy: 0.6765 - val_loss: 1.7878 - val_accuracy: 0.6703\n",
      "Epoch 94/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 1.7819 - accuracy: 0.6775 - val_loss: 1.7953 - val_accuracy: 0.6645\n",
      "Epoch 95/1000\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 1.7802 - accuracy: 0.6795 - val_loss: 1.7967 - val_accuracy: 0.6630\n",
      "Epoch 96/1000\n",
      "500/500 [==============================] - 58s 116ms/step - loss: 1.7821 - accuracy: 0.6776 - val_loss: 1.7852 - val_accuracy: 0.6741\n",
      "Epoch 97/1000\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 1.7813 - accuracy: 0.6790 - val_loss: 1.7819 - val_accuracy: 0.6776\n",
      "Epoch 98/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 1.7792 - accuracy: 0.6806 - val_loss: 1.7811 - val_accuracy: 0.6776\n",
      "Epoch 99/1000\n",
      "500/500 [==============================] - 59s 117ms/step - loss: 1.7818 - accuracy: 0.6778 - val_loss: 1.7904 - val_accuracy: 0.6696\n",
      "Epoch 100/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 1.7798 - accuracy: 0.6801 - val_loss: 1.8383 - val_accuracy: 0.6197\n",
      "Epoch 101/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.7814 - accuracy: 0.6781 - val_loss: 1.7833 - val_accuracy: 0.6754\n",
      "Epoch 102/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 1.7798 - accuracy: 0.6800 - val_loss: 1.7918 - val_accuracy: 0.6672\n",
      "Epoch 103/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7795 - accuracy: 0.6803 - val_loss: 1.7835 - val_accuracy: 0.6771\n",
      "Epoch 104/1000\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 1.7782 - accuracy: 0.6814 - val_loss: 1.7831 - val_accuracy: 0.6768\n",
      "Epoch 105/1000\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 1.7763 - accuracy: 0.6836 - val_loss: 1.7964 - val_accuracy: 0.6631\n",
      "Epoch 106/1000\n",
      "500/500 [==============================] - 62s 125ms/step - loss: 1.7770 - accuracy: 0.6826 - val_loss: 1.7870 - val_accuracy: 0.6718\n",
      "Epoch 107/1000\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 1.7780 - accuracy: 0.6816 - val_loss: 1.7829 - val_accuracy: 0.6770\n",
      "Epoch 108/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - ETA: 0s - loss: 1.7772 - accuracy: 0.6822\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 1.7772 - accuracy: 0.6822 - val_loss: 1.7964 - val_accuracy: 0.6627\n",
      "Epoch 109/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 1.7745 - accuracy: 0.6854 - val_loss: 1.7781 - val_accuracy: 0.6811\n",
      "Epoch 110/1000\n",
      "500/500 [==============================] - 59s 119ms/step - loss: 1.7722 - accuracy: 0.6874 - val_loss: 1.7768 - val_accuracy: 0.6839\n",
      "Epoch 111/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 1.7755 - accuracy: 0.6839 - val_loss: 1.7938 - val_accuracy: 0.6651\n",
      "Epoch 112/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.7733 - accuracy: 0.6863 - val_loss: 1.7819 - val_accuracy: 0.6782\n",
      "Epoch 113/1000\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 1.7727 - accuracy: 0.6872 - val_loss: 1.7782 - val_accuracy: 0.6815\n",
      "Epoch 114/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.7721 - accuracy: 0.6875 - val_loss: 1.7775 - val_accuracy: 0.6832\n",
      "Epoch 115/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 1.7738 - accuracy: 0.6860 - val_loss: 1.7811 - val_accuracy: 0.6782\n",
      "Epoch 116/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 1.7707 - accuracy: 0.6891 - val_loss: 1.7790 - val_accuracy: 0.6811\n",
      "Epoch 117/1000\n",
      "500/500 [==============================] - 63s 125ms/step - loss: 1.7705 - accuracy: 0.6884 - val_loss: 1.7795 - val_accuracy: 0.6796\n",
      "Epoch 118/1000\n",
      "500/500 [==============================] - 61s 122ms/step - loss: 1.7708 - accuracy: 0.6883 - val_loss: 1.7776 - val_accuracy: 0.6811\n",
      "Epoch 119/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 1.7716 - accuracy: 0.6885 - val_loss: 1.7827 - val_accuracy: 0.6759\n",
      "Epoch 120/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.7708 - accuracy: 0.6886\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "500/500 [==============================] - 56s 113ms/step - loss: 1.7708 - accuracy: 0.6886 - val_loss: 1.7782 - val_accuracy: 0.6808\n",
      "Epoch 121/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 1.7729 - accuracy: 0.6864 - val_loss: 1.7770 - val_accuracy: 0.6828\n",
      "Epoch 122/1000\n",
      "500/500 [==============================] - 59s 118ms/step - loss: 1.7697 - accuracy: 0.6904 - val_loss: 1.7749 - val_accuracy: 0.6841\n",
      "Epoch 123/1000\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 1.7686 - accuracy: 0.6913 - val_loss: 1.7739 - val_accuracy: 0.6865\n",
      "Epoch 124/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 1.7682 - accuracy: 0.6919 - val_loss: 1.7759 - val_accuracy: 0.6835\n",
      "Epoch 125/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.7683 - accuracy: 0.6914 - val_loss: 1.7735 - val_accuracy: 0.6867\n",
      "Epoch 126/1000\n",
      "500/500 [==============================] - 60s 121ms/step - loss: 1.7688 - accuracy: 0.6912 - val_loss: 1.7759 - val_accuracy: 0.6830\n",
      "Epoch 127/1000\n",
      "500/500 [==============================] - 60s 119ms/step - loss: 1.7703 - accuracy: 0.6896 - val_loss: 1.7749 - val_accuracy: 0.6845\n",
      "Epoch 128/1000\n",
      "500/500 [==============================] - 62s 124ms/step - loss: 1.7697 - accuracy: 0.6899 - val_loss: 1.7785 - val_accuracy: 0.6821\n",
      "Epoch 129/1000\n",
      "500/500 [==============================] - 61s 123ms/step - loss: 1.7693 - accuracy: 0.6906 - val_loss: 1.7750 - val_accuracy: 0.6852\n",
      "Epoch 130/1000\n",
      "500/500 [==============================] - 61s 121ms/step - loss: 1.7696 - accuracy: 0.6900 - val_loss: 1.7748 - val_accuracy: 0.6848\n",
      "Epoch 131/1000\n",
      "500/500 [==============================] - 58s 117ms/step - loss: 1.7666 - accuracy: 0.6931 - val_loss: 1.7734 - val_accuracy: 0.6870\n",
      "Epoch 132/1000\n",
      "500/500 [==============================] - 60s 120ms/step - loss: 1.7671 - accuracy: 0.6926 - val_loss: 1.7750 - val_accuracy: 0.6854\n",
      "Epoch 133/1000\n",
      "500/500 [==============================] - 53s 106ms/step - loss: 1.7667 - accuracy: 0.6931 - val_loss: 1.7754 - val_accuracy: 0.6850\n",
      "Epoch 134/1000\n",
      "500/500 [==============================] - 46s 93ms/step - loss: 1.7658 - accuracy: 0.6938 - val_loss: 1.7744 - val_accuracy: 0.6853\n",
      "Epoch 135/1000\n",
      "500/500 [==============================] - 46s 92ms/step - loss: 1.7690 - accuracy: 0.6907 - val_loss: 1.7762 - val_accuracy: 0.6836\n",
      "Epoch 136/1000\n",
      "500/500 [==============================] - 48s 96ms/step - loss: 1.7665 - accuracy: 0.6932 - val_loss: 1.7725 - val_accuracy: 0.6877\n",
      "Epoch 137/1000\n",
      "500/500 [==============================] - 48s 97ms/step - loss: 1.7658 - accuracy: 0.6934 - val_loss: 1.7718 - val_accuracy: 0.6874\n",
      "Epoch 138/1000\n",
      "500/500 [==============================] - 43s 86ms/step - loss: 1.7658 - accuracy: 0.6937 - val_loss: 1.7731 - val_accuracy: 0.6862\n",
      "Epoch 139/1000\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.7653 - accuracy: 0.6949 - val_loss: 1.7722 - val_accuracy: 0.6873\n",
      "Epoch 140/1000\n",
      "500/500 [==============================] - 47s 94ms/step - loss: 1.7666 - accuracy: 0.6937 - val_loss: 1.7718 - val_accuracy: 0.6878\n",
      "Epoch 141/1000\n",
      "500/500 [==============================] - 48s 95ms/step - loss: 1.7655 - accuracy: 0.6942 - val_loss: 1.7767 - val_accuracy: 0.6815\n",
      "Epoch 142/1000\n",
      "500/500 [==============================] - 47s 94ms/step - loss: 1.7660 - accuracy: 0.6934 - val_loss: 1.7724 - val_accuracy: 0.6870\n",
      "Epoch 143/1000\n",
      "500/500 [==============================] - 45s 91ms/step - loss: 1.7648 - accuracy: 0.6950 - val_loss: 1.7787 - val_accuracy: 0.6813\n",
      "Epoch 144/1000\n",
      "500/500 [==============================] - 45s 90ms/step - loss: 1.7644 - accuracy: 0.6951 - val_loss: 1.7719 - val_accuracy: 0.6871\n",
      "Epoch 145/1000\n",
      "500/500 [==============================] - 46s 91ms/step - loss: 1.7647 - accuracy: 0.6949 - val_loss: 1.7721 - val_accuracy: 0.6884\n",
      "Epoch 146/1000\n",
      "500/500 [==============================] - 46s 93ms/step - loss: 1.7665 - accuracy: 0.6933 - val_loss: 1.7724 - val_accuracy: 0.6861\n",
      "Epoch 147/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.7676 - accuracy: 0.6916\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "500/500 [==============================] - 47s 94ms/step - loss: 1.7676 - accuracy: 0.6916 - val_loss: 1.7733 - val_accuracy: 0.6865\n",
      "Epoch 148/1000\n",
      "500/500 [==============================] - 47s 95ms/step - loss: 1.7631 - accuracy: 0.6970 - val_loss: 1.7708 - val_accuracy: 0.6883\n",
      "Epoch 149/1000\n",
      "500/500 [==============================] - 47s 94ms/step - loss: 1.7644 - accuracy: 0.6950 - val_loss: 1.7704 - val_accuracy: 0.6896\n",
      "Epoch 150/1000\n",
      "500/500 [==============================] - 47s 94ms/step - loss: 1.7646 - accuracy: 0.6952 - val_loss: 1.7713 - val_accuracy: 0.6888\n",
      "Epoch 151/1000\n",
      "500/500 [==============================] - 44s 89ms/step - loss: 1.7634 - accuracy: 0.6972 - val_loss: 1.7711 - val_accuracy: 0.6872\n",
      "Epoch 152/1000\n",
      "500/500 [==============================] - 46s 92ms/step - loss: 1.7636 - accuracy: 0.6958 - val_loss: 1.7709 - val_accuracy: 0.6882\n",
      "Epoch 153/1000\n",
      "500/500 [==============================] - 46s 91ms/step - loss: 1.7645 - accuracy: 0.6950 - val_loss: 1.7715 - val_accuracy: 0.6880\n",
      "Epoch 154/1000\n",
      "500/500 [==============================] - 47s 94ms/step - loss: 1.7661 - accuracy: 0.6937 - val_loss: 1.7716 - val_accuracy: 0.6886\n",
      "Epoch 155/1000\n",
      "500/500 [==============================] - 47s 95ms/step - loss: 1.7619 - accuracy: 0.6980 - val_loss: 1.7706 - val_accuracy: 0.6893\n",
      "Epoch 156/1000\n",
      "500/500 [==============================] - 46s 93ms/step - loss: 1.7627 - accuracy: 0.6970 - val_loss: 1.7716 - val_accuracy: 0.6878\n",
      "Epoch 157/1000\n",
      "500/500 [==============================] - 46s 93ms/step - loss: 1.7634 - accuracy: 0.6967 - val_loss: 1.7708 - val_accuracy: 0.6894\n",
      "Epoch 158/1000\n",
      "500/500 [==============================] - 47s 94ms/step - loss: 1.7637 - accuracy: 0.6963 - val_loss: 1.7708 - val_accuracy: 0.6879\n",
      "Epoch 159/1000\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.7631 - accuracy: 0.6969\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "500/500 [==============================] - 47s 93ms/step - loss: 1.7631 - accuracy: 0.6969 - val_loss: 1.7710 - val_accuracy: 0.6890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/1000\n",
      "201/500 [===========>..................] - ETA: 26s - loss: 1.7660 - accuracy: 0.6937"
     ]
    }
   ],
   "source": [
    "# Fitting the CNN to the images\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10,  \n",
    "                              min_delta=1e-4, mode='min', verbose=1)\n",
    "\n",
    "stop_alg = EarlyStopping(monitor='val_loss', patience=35, \n",
    "                         restore_best_weights=True, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "hist = classifier.fit(train_data,  epochs=1000, \n",
    "                   callbacks=[stop_alg, reduce_lr], \n",
    "                      validation_steps=validation_steps,\n",
    "                      steps_per_epoch=steps_per_epoch,\n",
    "                   validation_data=test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
