{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CvD-15*15.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehang/Improvised-CNN/blob/master/notebook/Cats-Vs-Dogs/Resized%20cats%20vs%20dogs/CvD_15_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kgNE_6jo9jb",
        "outputId": "9386aa0f-97f4-47ee-8926-817774badbbe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENSIxqdDpTP6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pathlib\n",
        "import time\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWcoHmVSpblI"
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/Mehang\\ Rai/all-cats-vs-dogs.zip -d cats-vs-dogs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcbs_rsZpdyq"
      },
      "source": [
        "ITERATION = 1\n",
        "IMAGE_WIDTH=256\n",
        "IMAGE_HEIGHT=256\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3\n",
        "RANDOM_SEED = [42,42,34,56,62,74,29,15,7,81][ITERATION-1]\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 2\n",
        "EPOCHS = 1000\n",
        "GABOR_LAYER_INDEX = 0\n",
        "GABOR_WIDTH = 15\n",
        "GABOR_HEIGHT = 15\n",
        "GABOR_SIZE = (GABOR_WIDTH, GABOR_HEIGHT)\n",
        "NUM_RECEPTIVE_FILTERS = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFRSVtnDpjMk"
      },
      "source": [
        "filenames = os.listdir(\"cats-vs-dogs/all/\")\n",
        "categories = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'dog':\n",
        "        categories.append(1)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'filename': filenames,\n",
        "    'category': categories\n",
        "})\n",
        "\n",
        "df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'}) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvQf8lhlplsc"
      },
      "source": [
        "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=RANDOM_SEED)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)\n",
        "total_train = train_df.shape[0]\n",
        "total_validate = validate_df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "cp7vuo77p7Hu",
        "outputId": "eee87494-7b53-4875-e74b-05fc0e173774"
      },
      "source": [
        "train_df['category'].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc0fe017690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "WtW8Rj2Zp9yk",
        "outputId": "3a6e7e36-9c12-4ee3-b7ba-682440ce3246"
      },
      "source": [
        "validate_df['category'].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc0fdf5fd50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7skO3rXp_tM",
        "outputId": "61e219a3-04ed-4603-ef50-a847793c8ac7"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        ")\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df, \n",
        "    \"cats-vs-dogs/all/\", \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20000 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks1sL9GqqILi",
        "outputId": "02990717-64e9-4905-f1b5-4645099f1b75"
      },
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    validate_df, \n",
        "    \"cats-vs-dogs/all/\", \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5000 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfWd5Q2m2O9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3122cfe8-eae7-48e4-a142-16e35527feeb"
      },
      "source": [
        "print(train_df.shape)\n",
        "print(validate_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 2)\n",
            "(5000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCMN4FoI2Qej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7512168b-92c7-49e3-ddcd-7e55120835b4"
      },
      "source": [
        "train_generator.image_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC3dKEao2R2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7386457c-47c8-4816-9d18-77933115fc00"
      },
      "source": [
        "NUM_CLASSES = len(train_df['category'].value_counts())\n",
        "print(NUM_CLASSES)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgFg1mReqMXc",
        "outputId": "301196dd-f9bb-4cef-b2f6-f6694c657b90"
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Activation\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "classifier = None\n",
        "classifier = Sequential([\n",
        "    layers.Conv2D(NUM_RECEPTIVE_FILTERS, kernel_size=GABOR_SIZE, strides=(1,1), name=\"GaborLayer\", input_shape=train_generator.image_shape),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    Dropout(0.5),\n",
        "    layers.Conv2D(64, kernel_size=(3,3), strides=(2,2)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    Dropout(0.5),\n",
        "    layers.Conv2D(128, kernel_size=(3,3), strides=(2,2)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    Dropout(0.5),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation('relu'),\n",
        "    Dropout(0.5),\n",
        "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "classifier.summary()\n",
        "\n",
        "import copy\n",
        "untrained_layers = copy.deepcopy(classifier.get_layer(name=classifier.layers[GABOR_LAYER_INDEX].name).get_weights())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "GaborLayer (Conv2D)          (None, 242, 242, 32)      21632     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 242, 242, 32)      128       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 242, 242, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 121, 121, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 121, 121, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 60, 60, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 60, 60, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 60, 60, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 3,329,730\n",
            "Trainable params: 3,328,258\n",
            "Non-trainable params: 1,472\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUG7r7EXrEDW",
        "outputId": "a85d9baa-9c3f-4b63-945b-6beeb7798e2a"
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10,  \n",
        "                              min_delta=1e-4, mode='min', verbose=1)\n",
        "stop_alg = EarlyStopping(monitor='val_loss', patience=35, \n",
        "                         restore_best_weights=True, verbose=1)\n",
        "callbacks = [stop_alg, reduce_lr]\n",
        "opt = Adam(learning_rate=0.001)\n",
        "classifier.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', 'AUC'])\n",
        "\n",
        "start = time.perf_counter()\n",
        "hist = classifier.fit(\n",
        "    train_generator, \n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_validate//BATCH_SIZE,\n",
        "    steps_per_epoch=total_train//BATCH_SIZE,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "finish = time.perf_counter()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "625/625 [==============================] - 78s 98ms/step - loss: 0.8777 - accuracy: 0.5632 - auc: 0.5819 - val_loss: 0.8659 - val_accuracy: 0.5417 - val_auc: 0.6105\n",
            "Epoch 2/1000\n",
            "625/625 [==============================] - 60s 97ms/step - loss: 0.6102 - accuracy: 0.6728 - auc: 0.7330 - val_loss: 0.5685 - val_accuracy: 0.6971 - val_auc: 0.7737\n",
            "Epoch 3/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.5670 - accuracy: 0.7064 - auc: 0.7798 - val_loss: 0.5440 - val_accuracy: 0.7188 - val_auc: 0.7970\n",
            "Epoch 4/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.5318 - accuracy: 0.7343 - auc: 0.8104 - val_loss: 0.5426 - val_accuracy: 0.7202 - val_auc: 0.8008\n",
            "Epoch 5/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.5164 - accuracy: 0.7447 - auc: 0.8237 - val_loss: 0.5395 - val_accuracy: 0.7274 - val_auc: 0.8069\n",
            "Epoch 6/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.4916 - accuracy: 0.7634 - auc: 0.8428 - val_loss: 0.4861 - val_accuracy: 0.7622 - val_auc: 0.8457\n",
            "Epoch 7/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.4680 - accuracy: 0.7759 - auc: 0.8594 - val_loss: 0.4610 - val_accuracy: 0.7728 - val_auc: 0.8617\n",
            "Epoch 8/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.4448 - accuracy: 0.7912 - auc: 0.8737 - val_loss: 0.4610 - val_accuracy: 0.7804 - val_auc: 0.8627\n",
            "Epoch 9/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.4260 - accuracy: 0.8025 - auc: 0.8857 - val_loss: 0.4551 - val_accuracy: 0.7833 - val_auc: 0.8667\n",
            "Epoch 10/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.4134 - accuracy: 0.8109 - auc: 0.8927 - val_loss: 0.4327 - val_accuracy: 0.7959 - val_auc: 0.8809\n",
            "Epoch 11/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.4024 - accuracy: 0.8160 - auc: 0.8986 - val_loss: 0.4215 - val_accuracy: 0.8125 - val_auc: 0.8892\n",
            "Epoch 12/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.4025 - accuracy: 0.8137 - auc: 0.8986 - val_loss: 0.6725 - val_accuracy: 0.6659 - val_auc: 0.7616\n",
            "Epoch 13/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.3826 - accuracy: 0.8325 - auc: 0.9087 - val_loss: 0.3983 - val_accuracy: 0.8173 - val_auc: 0.9013\n",
            "Epoch 14/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.3515 - accuracy: 0.8474 - auc: 0.9241 - val_loss: 0.3996 - val_accuracy: 0.8207 - val_auc: 0.9008\n",
            "Epoch 15/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.3484 - accuracy: 0.8446 - auc: 0.9250 - val_loss: 0.4190 - val_accuracy: 0.8157 - val_auc: 0.8987\n",
            "Epoch 16/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.3391 - accuracy: 0.8502 - auc: 0.9294 - val_loss: 0.4555 - val_accuracy: 0.7943 - val_auc: 0.8762\n",
            "Epoch 17/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.3246 - accuracy: 0.8569 - auc: 0.9349 - val_loss: 0.4702 - val_accuracy: 0.7877 - val_auc: 0.8722\n",
            "Epoch 18/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.3229 - accuracy: 0.8625 - auc: 0.9359 - val_loss: 0.5682 - val_accuracy: 0.7484 - val_auc: 0.8397\n",
            "Epoch 19/1000\n",
            "625/625 [==============================] - 60s 96ms/step - loss: 0.2947 - accuracy: 0.8740 - auc: 0.9471 - val_loss: 0.4013 - val_accuracy: 0.8145 - val_auc: 0.9010\n",
            "Epoch 20/1000\n",
            "476/625 [=====================>........] - ETA: 11s - loss: 0.2916 - accuracy: 0.8715 - auc: 0.9480"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hO-YCAM2rer"
      },
      "source": [
        "classifier.layers[GABOR_LAYER_INDEX].name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiSUmiFLv323"
      },
      "source": [
        "print(\"Start time = {}\".format(start))\n",
        "print(\"Finish time = {}\".format(finish))\n",
        "print(\"Training time = {}\".format(finish-start))\n",
        "hist.history['start_time'] = start\n",
        "hist.history['finish_time'] = finish\n",
        "hist.history['train_time'] = finish-start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj0UMlbVWxUH"
      },
      "source": [
        "import pickle\n",
        "\n",
        "trained_layers = copy.deepcopy(classifier.get_layer(name=classifier.layers[GABOR_LAYER_INDEX].name).get_weights())\n",
        "hist.history['untrained_layers'] = untrained_layers\n",
        "hist.history['trained_layers'] = trained_layers\n",
        "\n",
        "with open('cvd-{}-history-kernel-{}.p'.format(ITERATION, GABOR_WIDTH),'wb') as fp:\n",
        "    pickle.dump(hist.history, fp, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89kyymwCsiie"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.plot(hist.history['loss'], color='#785ef0')\n",
        "plt.plot(hist.history['val_loss'], color='#dc267f')\n",
        "plt.title('Model Loss Progress')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Set', 'Test Set'], loc='upper right')\n",
        "plt.savefig('cvd-{}-loss-kernel-{}.png'.format(ITERATION,GABOR_WIDTH), dpi=350, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISg9BqqJsupA"
      },
      "source": [
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.plot(hist.history['accuracy'], color='#785ef0')\n",
        "plt.plot(hist.history['val_accuracy'], color='#dc267f')\n",
        "plt.title('Model Accuracy Progress')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Set', 'Test Set'], loc='upper right')\n",
        "plt.savefig('cvd-{}-accuracy-kernel-{}.png'.format(ITERATION, GABOR_WIDTH), dpi=350, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rCaMpXRs5c6"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "cnnl1 = classifier.layers[GABOR_LAYER_INDEX].name   # get the name of the first conv layer\n",
        "W = classifier.get_layer(name=cnnl1).get_weights()[0]   #get the filters\n",
        "wshape = W.shape  #save the original shape\n",
        "\n",
        "# this part will scale to [0, 1] for visualization purposes\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(W.reshape(-1,1))\n",
        "W = scaler.transform(W.reshape(-1,1))\n",
        "W = W.reshape(wshape)\n",
        "\n",
        "fig, axs = plt.subplots(8,NUM_RECEPTIVE_FILTERS//8, figsize=(24,24))\n",
        "fig.subplots_adjust(hspace = .25, wspace=.001)\n",
        "axs = axs.ravel()\n",
        "for i in range(W.shape[-1]):\n",
        "  # we reshape to a 3D (RGB) image shape and display\n",
        "  h = np.reshape(W[:,:,:,i], (GABOR_WIDTH,GABOR_HEIGHT,3))\n",
        "  axs[i].imshow(h)\n",
        "  axs[i].set_title('Filter ' + str(i))    \n",
        "plt.savefig(\"cvd-{}-filters-kernel-{}.png\".format(ITERATION,GABOR_WIDTH), bbox_inches='tight', dpi=350)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVGc1FmYs-80"
      },
      "source": [
        "cnnl1 = classifier.layers[GABOR_LAYER_INDEX].name   # get the name of the first conv layer\n",
        "W = classifier.get_layer(name=cnnl1).get_weights()[0]\n",
        "plt.hist(W.ravel(), bins=100)\n",
        "print(np.min(W),np.max(W))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgrLggl7wMom"
      },
      "source": [
        "filter_layers = []\n",
        "for i in range(NUM_RECEPTIVE_FILTERS):\n",
        "    for j in range(3):\n",
        "        filter_layers.append(np.reshape(W[:,:,j, i], GABOR_SIZE))\n",
        "for i,gf in enumerate(filter_layers):\n",
        "    plt.subplot(8, (W.shape[3]*3)//8, i+1)\n",
        "    plt.imshow(gf, cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.savefig(\"cvd-{}-channelwise-filters-kernel-{}.png\".format(ITERATION,GABOR_WIDTH), bbox_inches='tight', dpi=350)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQg1FMM9oFAa"
      },
      "source": [
        "!cp cvd-1-history-kernel-15.p /content/drive/My\\ Drive/Mehang\\ Rai/analysis/cats-vs-dogs/1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4yaVwSm3DzG"
      },
      "source": [
        "!cp cvd-1-loss-kernel-15.png /content/drive/My\\ Drive/Mehang\\ Rai/analysis/cats-vs-dogs/1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LRkny373EWo"
      },
      "source": [
        "!cp cvd-1-accuracy-kernel-15.png /content/drive/My\\ Drive/Mehang\\ Rai/analysis/cats-vs-dogs/1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVYtyKFA3GuR"
      },
      "source": [
        "!cp cvd-1-filters-kernel-15.png /content/drive/My\\ Drive/Mehang\\ Rai/analysis/cats-vs-dogs/1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgJVqrzI3IKS"
      },
      "source": [
        "!cp cvd-1-channelwise-filters-kernel-15.png /content/drive/My\\ Drive/Mehang\\ Rai/analysis/cats-vs-dogs/1/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdNws3wu5YWJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}