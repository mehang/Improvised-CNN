{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CvD-15*15.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMe2d7FGcmsxfY25odXDI+O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehang/Improvised-CNN/blob/master/notebook/Cats-Vs-Dogs/Resized%20cats%20vs%20dogs/CvD_15_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kgNE_6jo9jb",
        "outputId": "d4b5d2cb-3d96-4871-b3b4-cc806787889d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENSIxqdDpTP6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pathlib\n",
        "import time\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWcoHmVSpblI",
        "outputId": "e209152b-e628-4e16-b64f-ba2f77182903"
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/Gabor\\ Dataset/all-cats-vs-dogs.zip -d cats-vs-dogs"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Gabor Dataset/all-cats-vs-dogs.zip\n",
            "replace cats-vs-dogs/all/cat.203.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcbs_rsZpdyq"
      },
      "source": [
        "IMAGE_WIDTH=256\n",
        "IMAGE_HEIGHT=256\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3\n",
        "RANDOM_SEED = 42\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 2\n",
        "EPOCHS = 1000\n",
        "GABOR_LAYER_INDEX = 0\n",
        "GABOR_WIDTH = 15\n",
        "GABOR_HEIGHT = 15\n",
        "GABOR_SIZE = (GABOR_WIDTH, GABOR_HEIGHT)\n",
        "NUM_RECEPTIVE_FILTERS = 32"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFRSVtnDpjMk"
      },
      "source": [
        "filenames = os.listdir(\"cats-vs-dogs/all/\")\n",
        "categories = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'dog':\n",
        "        categories.append(1)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'filename': filenames,\n",
        "    'category': categories\n",
        "})\n",
        "\n",
        "df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'}) "
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvQf8lhlplsc"
      },
      "source": [
        "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=RANDOM_SEED)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)\n",
        "total_train = train_df.shape[0]\n",
        "total_validate = validate_df.shape[0]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "cp7vuo77p7Hu",
        "outputId": "533f79a9-3b9e-495d-a25e-37b4258ddfe4"
      },
      "source": [
        "train_df['category'].value_counts().plot.bar()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fed11d5de10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "WtW8Rj2Zp9yk",
        "outputId": "9a470ad5-ec36-4648-d92b-0f166e343d45"
      },
      "source": [
        "validate_df['category'].value_counts().plot.bar()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fede6375780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7skO3rXp_tM",
        "outputId": "05f4fc8c-a067-443c-bce3-cb34d95656a8"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        ")\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df, \n",
        "    \"cats-vs-dogs/all/\", \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20000 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks1sL9GqqILi",
        "outputId": "a0a1c068-c7ea-4fb6-8e48-3ab433cacb78"
      },
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    validate_df, \n",
        "    \"cats-vs-dogs/all/\", \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5000 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgFg1mReqMXc",
        "outputId": "4fac3c16-0001-4110-e7bf-e65c68a2ef9b"
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Activation\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "classifier = None\n",
        "classifier = Sequential([\n",
        "    layers.Conv2D(NUM_RECEPTIVE_FILTERS, kernel_size=GABOR_SIZE, strides=(1,1), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    Dropout(0.5),\n",
        "    layers.Conv2D(64, kernel_size=(3,3), strides=(2,2), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    Dropout(0.5),\n",
        "    layers.Conv2D(128, kernel_size=(3,3), strides=(2,2), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    Dropout(0.5),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "classifier.summary()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 242, 242, 32)      21632     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 242, 242, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 121, 121, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 121, 121, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 60, 60, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 60, 60, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 3,329,730\n",
            "Trainable params: 3,328,258\n",
            "Non-trainable params: 1,472\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUG7r7EXrEDW",
        "outputId": "15c8a280-690a-44d5-c166-02d9e8fb0814"
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10,  \n",
        "                              min_delta=1e-4, mode='min', verbose=1)\n",
        "stop_alg = EarlyStopping(monitor='val_loss', patience=35, \n",
        "                         restore_best_weights=True, verbose=1)\n",
        "callbacks = [stop_alg, reduce_lr]\n",
        "opt = RMSprop(learning_rate=0.001)\n",
        "classifier.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "start = time.perf_counter()\n",
        "hist = classifier.fit(\n",
        "    train_generator, \n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_validate//BATCH_SIZE,\n",
        "    steps_per_epoch=total_train//BATCH_SIZE,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "finish = time.perf_counter()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.7882 - accuracy: 0.6005 - val_loss: 0.6450 - val_accuracy: 0.6214\n",
            "Epoch 2/1000\n",
            "625/625 [==============================] - 73s 116ms/step - loss: 0.6116 - accuracy: 0.6757 - val_loss: 0.5731 - val_accuracy: 0.7023\n",
            "Epoch 3/1000\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.5687 - accuracy: 0.7082 - val_loss: 0.5124 - val_accuracy: 0.7412\n",
            "Epoch 4/1000\n",
            "625/625 [==============================] - 70s 112ms/step - loss: 0.5362 - accuracy: 0.7350 - val_loss: 0.5829 - val_accuracy: 0.7141\n",
            "Epoch 5/1000\n",
            "625/625 [==============================] - 70s 112ms/step - loss: 0.5088 - accuracy: 0.7521 - val_loss: 0.5599 - val_accuracy: 0.7238\n",
            "Epoch 6/1000\n",
            "625/625 [==============================] - 69s 110ms/step - loss: 0.4916 - accuracy: 0.7653 - val_loss: 0.5472 - val_accuracy: 0.7334\n",
            "Epoch 7/1000\n",
            "625/625 [==============================] - 69s 111ms/step - loss: 0.4783 - accuracy: 0.7749 - val_loss: 0.4630 - val_accuracy: 0.7792\n",
            "Epoch 8/1000\n",
            "625/625 [==============================] - 68s 109ms/step - loss: 0.4645 - accuracy: 0.7844 - val_loss: 0.6150 - val_accuracy: 0.7344\n",
            "Epoch 9/1000\n",
            "625/625 [==============================] - 69s 110ms/step - loss: 0.4469 - accuracy: 0.7922 - val_loss: 0.5005 - val_accuracy: 0.7678\n",
            "Epoch 10/1000\n",
            "625/625 [==============================] - 69s 110ms/step - loss: 0.4367 - accuracy: 0.8008 - val_loss: 0.7164 - val_accuracy: 0.7109\n",
            "Epoch 11/1000\n",
            "625/625 [==============================] - 68s 109ms/step - loss: 0.4246 - accuracy: 0.8088 - val_loss: 0.4511 - val_accuracy: 0.7955\n",
            "Epoch 12/1000\n",
            "625/625 [==============================] - 68s 109ms/step - loss: 0.4174 - accuracy: 0.8118 - val_loss: 0.4566 - val_accuracy: 0.7762\n",
            "Epoch 13/1000\n",
            "625/625 [==============================] - 68s 109ms/step - loss: 0.4106 - accuracy: 0.8158 - val_loss: 0.4702 - val_accuracy: 0.7863\n",
            "Epoch 14/1000\n",
            "625/625 [==============================] - 68s 109ms/step - loss: 0.4035 - accuracy: 0.8198 - val_loss: 0.5050 - val_accuracy: 0.7676\n",
            "Epoch 15/1000\n",
            "625/625 [==============================] - 67s 108ms/step - loss: 0.3874 - accuracy: 0.8278 - val_loss: 0.4419 - val_accuracy: 0.7999\n",
            "Epoch 16/1000\n",
            "625/625 [==============================] - 67s 108ms/step - loss: 0.3874 - accuracy: 0.8268 - val_loss: 0.5904 - val_accuracy: 0.6599\n",
            "Epoch 17/1000\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.3802 - accuracy: 0.8310 - val_loss: 0.4578 - val_accuracy: 0.8095\n",
            "Epoch 18/1000\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.3719 - accuracy: 0.8368 - val_loss: 0.4733 - val_accuracy: 0.7568\n",
            "Epoch 19/1000\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.3667 - accuracy: 0.8382 - val_loss: 0.4619 - val_accuracy: 0.7770\n",
            "Epoch 20/1000\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.3616 - accuracy: 0.8439 - val_loss: 0.3945 - val_accuracy: 0.8263\n",
            "Epoch 21/1000\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.3480 - accuracy: 0.8503 - val_loss: 0.4274 - val_accuracy: 0.7999\n",
            "Epoch 22/1000\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.3482 - accuracy: 0.8490 - val_loss: 0.4097 - val_accuracy: 0.8153\n",
            "Epoch 23/1000\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.3441 - accuracy: 0.8529 - val_loss: 0.3886 - val_accuracy: 0.8331\n",
            "Epoch 24/1000\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.3345 - accuracy: 0.8569 - val_loss: 0.5196 - val_accuracy: 0.7344\n",
            "Epoch 25/1000\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.3333 - accuracy: 0.8595 - val_loss: 0.3938 - val_accuracy: 0.8271\n",
            "Epoch 26/1000\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.3279 - accuracy: 0.8603 - val_loss: 0.3892 - val_accuracy: 0.8307\n",
            "Epoch 27/1000\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.3265 - accuracy: 0.8640 - val_loss: 0.4514 - val_accuracy: 0.7859\n",
            "Epoch 28/1000\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.3184 - accuracy: 0.8666 - val_loss: 0.3582 - val_accuracy: 0.8450\n",
            "Epoch 29/1000\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.3142 - accuracy: 0.8673 - val_loss: 0.4430 - val_accuracy: 0.8009\n",
            "Epoch 30/1000\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.3016 - accuracy: 0.8751 - val_loss: 0.5642 - val_accuracy: 0.7135\n",
            "Epoch 31/1000\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.3024 - accuracy: 0.8740 - val_loss: 0.4102 - val_accuracy: 0.8203\n",
            "Epoch 32/1000\n",
            "625/625 [==============================] - 67s 107ms/step - loss: 0.3007 - accuracy: 0.8770 - val_loss: 0.3550 - val_accuracy: 0.8508\n",
            "Epoch 33/1000\n",
            "625/625 [==============================] - 68s 108ms/step - loss: 0.2987 - accuracy: 0.8770 - val_loss: 0.3525 - val_accuracy: 0.8518\n",
            "Epoch 34/1000\n",
            "625/625 [==============================] - 68s 109ms/step - loss: 0.2868 - accuracy: 0.8823 - val_loss: 0.4035 - val_accuracy: 0.8279\n",
            "Epoch 35/1000\n",
            "625/625 [==============================] - 69s 111ms/step - loss: 0.2866 - accuracy: 0.8826 - val_loss: 0.6426 - val_accuracy: 0.7630\n",
            "Epoch 36/1000\n",
            "625/625 [==============================] - 71s 113ms/step - loss: 0.2833 - accuracy: 0.8854 - val_loss: 0.3776 - val_accuracy: 0.8444\n",
            "Epoch 37/1000\n",
            "625/625 [==============================] - 69s 111ms/step - loss: 0.2765 - accuracy: 0.8877 - val_loss: 0.4123 - val_accuracy: 0.8255\n",
            "Epoch 38/1000\n",
            "625/625 [==============================] - 70s 112ms/step - loss: 0.2713 - accuracy: 0.8921 - val_loss: 0.3937 - val_accuracy: 0.8329\n",
            "Epoch 39/1000\n",
            "625/625 [==============================] - 69s 111ms/step - loss: 0.2704 - accuracy: 0.8906 - val_loss: 0.4333 - val_accuracy: 0.8091\n",
            "Epoch 40/1000\n",
            "625/625 [==============================] - 69s 110ms/step - loss: 0.2595 - accuracy: 0.8960 - val_loss: 0.4004 - val_accuracy: 0.8297\n",
            "Epoch 41/1000\n",
            "625/625 [==============================] - 70s 111ms/step - loss: 0.2623 - accuracy: 0.8963 - val_loss: 0.4351 - val_accuracy: 0.8069\n",
            "Epoch 42/1000\n",
            "625/625 [==============================] - 69s 111ms/step - loss: 0.2524 - accuracy: 0.8977 - val_loss: 0.4324 - val_accuracy: 0.8183\n",
            "Epoch 43/1000\n",
            "625/625 [==============================] - 70s 112ms/step - loss: 0.2513 - accuracy: 0.9006 - val_loss: 0.3348 - val_accuracy: 0.8594\n",
            "Epoch 44/1000\n",
            "625/625 [==============================] - 68s 109ms/step - loss: 0.2490 - accuracy: 0.8997 - val_loss: 0.3200 - val_accuracy: 0.8600\n",
            "Epoch 45/1000\n",
            "625/625 [==============================] - 68s 109ms/step - loss: 0.2359 - accuracy: 0.9075 - val_loss: 0.3469 - val_accuracy: 0.8498\n",
            "Epoch 46/1000\n",
            "110/625 [====>.........................] - ETA: 46s - loss: 0.2243 - accuracy: 0.9114"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiSUmiFLv323"
      },
      "source": [
        "print(\"Start time = {}\".format(start))\n",
        "print(\"Finish time = {}\".format(finish))\n",
        "print(\"Training time = {}\".format(finish-start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89kyymwCsiie"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.plot(hist.history['loss'], color='#785ef0')\n",
        "plt.plot(hist.history['val_loss'], color='#dc267f')\n",
        "plt.title('Model Loss Progress')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Set', 'Test Set'], loc='upper right')\n",
        "plt.savefig('cvd-loss-{}*{}.png'.format(GABOR_WIDTH, GABOR_HEIGHT), dpi=350, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISg9BqqJsupA"
      },
      "source": [
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.plot(hist.history['accuracy'], color='#785ef0')\n",
        "plt.plot(hist.history['val_accuracy'], color='#dc267f')\n",
        "plt.title('Model Accuracy Progress')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training Set', 'Test Set'], loc='upper right')\n",
        "plt.savefig('cvd-accuracy-{}*{}.png'.format(GABOR_WIDTH, GABOR_HEIGHT), dpi=350, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rCaMpXRs5c6"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "cnnl1 = classifier.layers[GABOR_LAYER_INDEX].name   # get the name of the first conv layer\n",
        "W = classifier.get_layer(name=cnnl1).get_weights()[0]   #get the filters\n",
        "wshape = W.shape  #save the original shape\n",
        "\n",
        "# this part will scale to [0, 1] for visualization purposes\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(W.reshape(-1,1))\n",
        "W = scaler.transform(W.reshape(-1,1))\n",
        "W = W.reshape(wshape)\n",
        "\n",
        "fig, axs = plt.subplots(8,NUM_RECEPTIVE_FILTERS//8, figsize=(24,24))\n",
        "fig.subplots_adjust(hspace = .25, wspace=.001)\n",
        "axs = axs.ravel()\n",
        "for i in range(W.shape[-1]):\n",
        "  # we reshape to a 3D (RGB) image shape and display\n",
        "  h = np.reshape(W[:,:,:,i], (GABOR_WIDTH,GABOR_HEIGHT,3))\n",
        "  axs[i].imshow(h)\n",
        "  axs[i].set_title('Filter ' + str(i))    \n",
        "plt.savefig(\"cvd-filters-{}*{}.png\".format(GABOR_WIDTH, GABOR_HEIGHT), bbox_inches='tight', dpi=350)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVGc1FmYs-80"
      },
      "source": [
        "cnnl1 = classifier.layers[GABOR_LAYER_INDEX].name   # get the name of the first conv layer\n",
        "W = classifier.get_layer(name=cnnl1).get_weights()[0]\n",
        "plt.hist(W.ravel(), bins=100)\n",
        "print(np.min(W),np.max(W))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgrLggl7wMom"
      },
      "source": [
        "filter_layers = []\n",
        "for i in range(NUM_RECEPTIVE_FILTERS):\n",
        "    for j in range(3):\n",
        "        filter_layers.append(np.reshape(W[:,:,j, i], GABOR_SIZE))\n",
        "for i,gf in enumerate(filter_layers):\n",
        "    plt.subplot(8, (W.shape[3]*3)//8, i+1)\n",
        "    plt.imshow(gf, cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.savefig(\"cvd-channelwise-filters-{}*{}.png\".format(GABOR_WIDTH, GABOR_HEIGHT), bbox_inches='tight', dpi=350)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQg1FMM9oFAa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}